{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font', family='AppleGothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_pos = pd.read_csv(\"pp.csv\")\n",
    "pos_neg = pd.read_csv(\"pn.csv\")\n",
    "neg_pos = pd.read_csv(\"np.csv\")\n",
    "neg_neg = pd.read_csv(\"nn.csv\")\n",
    "\n",
    "gender = pd.read_csv('all_gender.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocal</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final_dataset/이정_겨울봄.wav</td>\n",
       "      <td>4022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Final_dataset/버즈_거짓말.wav</td>\n",
       "      <td>4234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final_dataset/김광석_너무 깊이 생각하지마.wav</td>\n",
       "      <td>4411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Final_dataset/소찬휘_크게 라디오를 켜고.wav</td>\n",
       "      <td>4229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Final_dataset/이적_당연한 것들.wav</td>\n",
       "      <td>4493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               vocal  label  gender\n",
       "0           Final_dataset/이정_겨울봄.wav   4022       0\n",
       "1           Final_dataset/버즈_거짓말.wav   4234       0\n",
       "2  Final_dataset/김광석_너무 깊이 생각하지마.wav   4411       0\n",
       "3   Final_dataset/소찬휘_크게 라디오를 켜고.wav   4229       1\n",
       "4        Final_dataset/이적_당연한 것들.wav   4493       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 4500), (256, 4500), (256, 4500), (256, 4500))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pos.shape, pos_neg.shape, neg_pos.shape, neg_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_df = neg_pos.T.reset_index()\n",
    "df = np_df.merge(gender[['vocal', 'gender']], left_on='index', right_on='vocal', how='left').drop('vocal', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = df.drop(['index', 'gender'], axis=1)\n",
    "target = df[['gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(ftr, target, test_size=.1, stratify=target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4050, 256), (450, 256), (4050, 1), (450, 1))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3600, 32), (900, 32))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import umap\n",
    "# reducer = umap.UMAP(n_components=32)\n",
    "\n",
    "# x_train = reducer.fit_transform(x_train)\n",
    "# x_valid = reducer.transform(x_valid)\n",
    "# x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=4000, class_weight='balanced_subsample')\n",
    "rf.fit(x_train, y_train)\n",
    "rf_pred = rf.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7861635220125786"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(rf_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target['gender'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.84      0.93      0.88       276\n",
      "      female       0.87      0.72      0.79       174\n",
      "\n",
      "    accuracy                           0.85       450\n",
      "   macro avg       0.85      0.82      0.83       450\n",
      "weighted avg       0.85      0.85      0.85       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, rf_pred, target_names=['male', 'female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:12:39] WARNING: /tmp/xgboost/src/learner.cc:547: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:12:39] WARNING: /tmp/xgboost/src/learner.cc:1039: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state=42, n_estimators=4000, class_weight='balanced_subsample')\n",
    "xgb.fit(x_train, y_train)\n",
    "xgb_pred = xgb.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734138972809668"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(xgb_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.84      0.89      0.87       276\n",
      "      female       0.82      0.74      0.77       174\n",
      "\n",
      "    accuracy                           0.83       450\n",
      "   macro avg       0.83      0.82      0.82       450\n",
      "weighted avg       0.83      0.83      0.83       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, xgb_pred, target_names=['male', 'female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q ngboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.6672 val_loss=0.6489 scale=4.0000 norm=8.0000\n",
      "[iter 100] loss=0.3324 val_loss=0.3835 scale=2.0000 norm=3.1882\n",
      "[iter 200] loss=0.3073 val_loss=0.3784 scale=1.0000 norm=1.6088\n",
      "[iter 300] loss=0.2973 val_loss=0.3814 scale=1.0000 norm=1.6083\n",
      "[iter 400] loss=0.2922 val_loss=0.3858 scale=0.5000 norm=0.8038\n",
      "[iter 500] loss=0.2901 val_loss=0.3909 scale=0.2500 norm=0.4030\n",
      "[iter 600] loss=0.2886 val_loss=0.3940 scale=0.2500 norm=0.4026\n",
      "== Early stopping achieved.\n",
      "== Best iteration / VAL167 (val_loss=0.3775)\n"
     ]
    }
   ],
   "source": [
    "from ngboost import NGBClassifier\n",
    "from ngboost.distns import categorical\n",
    "from ngboost.scores import Score, MLE, CRPS\n",
    "\n",
    "ngb = NGBClassifier(random_state=42, n_estimators=2000,\n",
    "                    Dist=categorical.k_categorical(2),\n",
    "                    Base=default_tree_learner,\n",
    "                    minibatch_frac=1.0,\n",
    "                    Score=MLE)\n",
    "ngb.fit(X=x_train, Y=y_train, X_val=x_valid, Y_val=y_valid, early_stopping_rounds=500)\n",
    "ngb_pred = ngb.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7774294670846394"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ngb_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.84      0.92      0.88       276\n",
      "      female       0.86      0.71      0.78       174\n",
      "\n",
      "    accuracy                           0.84       450\n",
      "   macro avg       0.85      0.82      0.83       450\n",
      "weighted avg       0.84      0.84      0.84       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, ngb_pred, target_names=['male', 'female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ext = ExtraTreesClassifier(random_state=42, n_estimators=4000, class_weight='balanced')\n",
    "ext.fit(x_train, y_train)\n",
    "ext_pred = ext.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7749999999999999"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ext_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.84      0.92      0.88       276\n",
      "      female       0.85      0.71      0.77       174\n",
      "\n",
      "    accuracy                           0.84       450\n",
      "   macro avg       0.84      0.82      0.83       450\n",
      "weighted avg       0.84      0.84      0.84       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, ext_pred, target_names=['male', 'female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reset_index(drop=True)\n",
    "x_valid = x_valid.reset_index(drop=True)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4050, 256), (4050, 1))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.values.shape, y_train.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 162.01428| val_0_unsup_loss_numpy: 2.7197799682617188|  0:00:01s\n",
      "epoch 1  | loss: 1.64335 | val_0_unsup_loss_numpy: 1.1120799779891968|  0:00:02s\n",
      "epoch 2  | loss: 0.95234 | val_0_unsup_loss_numpy: 1.2578699588775635|  0:00:03s\n",
      "epoch 3  | loss: 0.8974  | val_0_unsup_loss_numpy: 1.2454899549484253|  0:00:04s\n",
      "epoch 4  | loss: 0.8855  | val_0_unsup_loss_numpy: 1.0815800428390503|  0:00:05s\n",
      "epoch 5  | loss: 0.83056 | val_0_unsup_loss_numpy: 1.0029900074005127|  0:00:06s\n",
      "epoch 6  | loss: 0.78682 | val_0_unsup_loss_numpy: 1.0521299839019775|  0:00:08s\n",
      "epoch 7  | loss: 0.72826 | val_0_unsup_loss_numpy: 1.0008000135421753|  0:00:09s\n",
      "epoch 8  | loss: 0.68412 | val_0_unsup_loss_numpy: 0.977840006351471|  0:00:10s\n",
      "epoch 9  | loss: 0.65076 | val_0_unsup_loss_numpy: 0.951170027256012|  0:00:11s\n",
      "epoch 10 | loss: 0.62476 | val_0_unsup_loss_numpy: 0.8807399868965149|  0:00:12s\n",
      "epoch 11 | loss: 0.58777 | val_0_unsup_loss_numpy: 0.8507400155067444|  0:00:14s\n",
      "epoch 12 | loss: 0.56576 | val_0_unsup_loss_numpy: 0.7694399952888489|  0:00:15s\n",
      "epoch 13 | loss: 0.5488  | val_0_unsup_loss_numpy: 0.8200799822807312|  0:00:16s\n",
      "epoch 14 | loss: 0.53002 | val_0_unsup_loss_numpy: 0.7717300057411194|  0:00:17s\n",
      "epoch 15 | loss: 0.51585 | val_0_unsup_loss_numpy: 0.6934199929237366|  0:00:18s\n",
      "epoch 16 | loss: 0.50602 | val_0_unsup_loss_numpy: 0.6443399786949158|  0:00:19s\n",
      "epoch 17 | loss: 0.48893 | val_0_unsup_loss_numpy: 0.5948500037193298|  0:00:21s\n",
      "epoch 18 | loss: 0.46663 | val_0_unsup_loss_numpy: 0.5084599852561951|  0:00:22s\n",
      "epoch 19 | loss: 0.46005 | val_0_unsup_loss_numpy: 0.49966999888420105|  0:00:23s\n",
      "epoch 20 | loss: 0.44957 | val_0_unsup_loss_numpy: 0.48761001229286194|  0:00:24s\n",
      "epoch 21 | loss: 0.44823 | val_0_unsup_loss_numpy: 0.4303100109100342|  0:00:25s\n",
      "epoch 22 | loss: 0.42324 | val_0_unsup_loss_numpy: 0.4216800034046173|  0:00:26s\n",
      "epoch 23 | loss: 0.40691 | val_0_unsup_loss_numpy: 0.38787001371383667|  0:00:27s\n",
      "epoch 24 | loss: 0.40282 | val_0_unsup_loss_numpy: 0.38863998651504517|  0:00:28s\n",
      "epoch 25 | loss: 0.39662 | val_0_unsup_loss_numpy: 0.3443300127983093|  0:00:30s\n",
      "epoch 26 | loss: 0.38545 | val_0_unsup_loss_numpy: 0.32001999020576477|  0:00:31s\n",
      "epoch 27 | loss: 0.36982 | val_0_unsup_loss_numpy: 0.3326199948787689|  0:00:32s\n",
      "epoch 28 | loss: 0.37634 | val_0_unsup_loss_numpy: 0.3261899948120117|  0:00:33s\n",
      "epoch 29 | loss: 0.36376 | val_0_unsup_loss_numpy: 0.30667001008987427|  0:00:34s\n",
      "epoch 30 | loss: 0.35351 | val_0_unsup_loss_numpy: 0.30469000339508057|  0:00:35s\n",
      "epoch 31 | loss: 0.35717 | val_0_unsup_loss_numpy: 0.2981100082397461|  0:00:36s\n",
      "epoch 32 | loss: 0.34857 | val_0_unsup_loss_numpy: 0.31000998616218567|  0:00:37s\n",
      "epoch 33 | loss: 0.35209 | val_0_unsup_loss_numpy: 0.30908000469207764|  0:00:38s\n",
      "epoch 34 | loss: 0.3415  | val_0_unsup_loss_numpy: 0.2879599928855896|  0:00:39s\n",
      "epoch 35 | loss: 0.34398 | val_0_unsup_loss_numpy: 0.29381000995635986|  0:00:41s\n",
      "epoch 36 | loss: 0.33229 | val_0_unsup_loss_numpy: 0.30410999059677124|  0:00:42s\n",
      "epoch 37 | loss: 0.34098 | val_0_unsup_loss_numpy: 0.32778000831604004|  0:00:43s\n",
      "epoch 38 | loss: 0.33459 | val_0_unsup_loss_numpy: 0.3010700047016144|  0:00:44s\n",
      "epoch 39 | loss: 0.33106 | val_0_unsup_loss_numpy: 0.2743600010871887|  0:00:45s\n",
      "epoch 40 | loss: 0.32494 | val_0_unsup_loss_numpy: 0.2817800045013428|  0:00:46s\n",
      "epoch 41 | loss: 0.3244  | val_0_unsup_loss_numpy: 0.23928000032901764|  0:00:47s\n",
      "epoch 42 | loss: 0.32118 | val_0_unsup_loss_numpy: 0.2927600145339966|  0:00:49s\n",
      "epoch 43 | loss: 0.31467 | val_0_unsup_loss_numpy: 0.2467699944972992|  0:00:50s\n",
      "epoch 44 | loss: 0.31385 | val_0_unsup_loss_numpy: 0.2506600022315979|  0:00:51s\n",
      "epoch 45 | loss: 0.30928 | val_0_unsup_loss_numpy: 0.28863999247550964|  0:00:52s\n",
      "epoch 46 | loss: 0.30692 | val_0_unsup_loss_numpy: 0.2781200110912323|  0:00:53s\n",
      "epoch 47 | loss: 0.30849 | val_0_unsup_loss_numpy: 0.305510014295578|  0:00:54s\n",
      "epoch 48 | loss: 0.31592 | val_0_unsup_loss_numpy: 0.29802998900413513|  0:00:55s\n",
      "epoch 49 | loss: 0.30774 | val_0_unsup_loss_numpy: 0.3212699890136719|  0:00:56s\n",
      "epoch 50 | loss: 0.31457 | val_0_unsup_loss_numpy: 0.27595001459121704|  0:00:58s\n",
      "epoch 51 | loss: 0.30712 | val_0_unsup_loss_numpy: 0.260919988155365|  0:00:59s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_unsup_loss_numpy = 0.23928000032901764\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
    "\n",
    "unsupervised_model = TabNetPretrainer(optimizer_fn=torch.optim.Adam,\n",
    "                                      optimizer_params=dict(lr=2e-2),\n",
    "                                      mask_type=\"entmax\",\n",
    "                                      n_shared_decoder=1,\n",
    "                                      n_indep_decoder=1)\n",
    "unsupervised_model.fit(X_train=x_train.values,\n",
    "                       eval_set=[x_valid.values],\n",
    "                       pretraining_ratio=0.8,\n",
    "                       batch_size=128,\n",
    "                       virtual_batch_size=64,\n",
    "                       drop_last=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.42485 | train_accuracy: 0.83778 | valid_accuracy: 0.83778 |  0:00:01s\n",
      "epoch 1  | loss: 0.39756 | train_accuracy: 0.81778 | valid_accuracy: 0.80889 |  0:00:02s\n",
      "epoch 2  | loss: 0.37092 | train_accuracy: 0.84469 | valid_accuracy: 0.84444 |  0:00:03s\n",
      "epoch 3  | loss: 0.36949 | train_accuracy: 0.82148 | valid_accuracy: 0.81111 |  0:00:04s\n",
      "epoch 4  | loss: 0.3808  | train_accuracy: 0.83531 | valid_accuracy: 0.81778 |  0:00:05s\n",
      "epoch 5  | loss: 0.37104 | train_accuracy: 0.84222 | valid_accuracy: 0.84222 |  0:00:06s\n",
      "epoch 6  | loss: 0.36964 | train_accuracy: 0.85259 | valid_accuracy: 0.85111 |  0:00:08s\n",
      "epoch 7  | loss: 0.36824 | train_accuracy: 0.84765 | valid_accuracy: 0.84222 |  0:00:09s\n",
      "epoch 8  | loss: 0.37929 | train_accuracy: 0.84815 | valid_accuracy: 0.83111 |  0:00:10s\n",
      "epoch 9  | loss: 0.37217 | train_accuracy: 0.84889 | valid_accuracy: 0.85111 |  0:00:11s\n",
      "epoch 10 | loss: 0.35265 | train_accuracy: 0.82222 | valid_accuracy: 0.81778 |  0:00:12s\n",
      "epoch 11 | loss: 0.36945 | train_accuracy: 0.85778 | valid_accuracy: 0.85333 |  0:00:13s\n",
      "epoch 12 | loss: 0.36567 | train_accuracy: 0.85111 | valid_accuracy: 0.83556 |  0:00:15s\n",
      "epoch 13 | loss: 0.3758  | train_accuracy: 0.84123 | valid_accuracy: 0.82667 |  0:00:16s\n",
      "epoch 14 | loss: 0.37078 | train_accuracy: 0.84593 | valid_accuracy: 0.83556 |  0:00:17s\n",
      "epoch 15 | loss: 0.35885 | train_accuracy: 0.8358  | valid_accuracy: 0.81111 |  0:00:18s\n",
      "epoch 16 | loss: 0.36569 | train_accuracy: 0.85704 | valid_accuracy: 0.85111 |  0:00:19s\n",
      "epoch 17 | loss: 0.34516 | train_accuracy: 0.84815 | valid_accuracy: 0.81778 |  0:00:20s\n",
      "epoch 18 | loss: 0.35901 | train_accuracy: 0.85531 | valid_accuracy: 0.85556 |  0:00:22s\n",
      "epoch 19 | loss: 0.35493 | train_accuracy: 0.84864 | valid_accuracy: 0.84444 |  0:00:23s\n",
      "epoch 20 | loss: 0.35606 | train_accuracy: 0.86049 | valid_accuracy: 0.86    |  0:00:24s\n",
      "epoch 21 | loss: 0.35707 | train_accuracy: 0.85259 | valid_accuracy: 0.84667 |  0:00:25s\n",
      "epoch 22 | loss: 0.34076 | train_accuracy: 0.8442  | valid_accuracy: 0.83333 |  0:00:26s\n",
      "epoch 23 | loss: 0.33673 | train_accuracy: 0.84914 | valid_accuracy: 0.82889 |  0:00:27s\n",
      "epoch 24 | loss: 0.33289 | train_accuracy: 0.84617 | valid_accuracy: 0.82889 |  0:00:28s\n",
      "epoch 25 | loss: 0.34809 | train_accuracy: 0.86049 | valid_accuracy: 0.83778 |  0:00:30s\n",
      "epoch 26 | loss: 0.31891 | train_accuracy: 0.85975 | valid_accuracy: 0.84222 |  0:00:31s\n",
      "epoch 27 | loss: 0.33717 | train_accuracy: 0.85926 | valid_accuracy: 0.84222 |  0:00:32s\n",
      "epoch 28 | loss: 0.33579 | train_accuracy: 0.86691 | valid_accuracy: 0.83111 |  0:00:33s\n",
      "epoch 29 | loss: 0.36347 | train_accuracy: 0.86543 | valid_accuracy: 0.82667 |  0:00:34s\n",
      "epoch 30 | loss: 0.35529 | train_accuracy: 0.83605 | valid_accuracy: 0.80444 |  0:00:35s\n",
      "epoch 31 | loss: 0.34465 | train_accuracy: 0.8516  | valid_accuracy: 0.82889 |  0:00:37s\n",
      "epoch 32 | loss: 0.33915 | train_accuracy: 0.86    | valid_accuracy: 0.83778 |  0:00:38s\n",
      "epoch 33 | loss: 0.34077 | train_accuracy: 0.85185 | valid_accuracy: 0.84    |  0:00:39s\n",
      "epoch 34 | loss: 0.34756 | train_accuracy: 0.85802 | valid_accuracy: 0.83333 |  0:00:40s\n",
      "epoch 35 | loss: 0.32354 | train_accuracy: 0.8637  | valid_accuracy: 0.83778 |  0:00:41s\n",
      "epoch 36 | loss: 0.33006 | train_accuracy: 0.86173 | valid_accuracy: 0.82444 |  0:00:42s\n",
      "epoch 37 | loss: 0.33201 | train_accuracy: 0.87086 | valid_accuracy: 0.83333 |  0:00:44s\n",
      "epoch 38 | loss: 0.33015 | train_accuracy: 0.87111 | valid_accuracy: 0.83556 |  0:00:45s\n",
      "epoch 39 | loss: 0.32116 | train_accuracy: 0.86123 | valid_accuracy: 0.80889 |  0:00:46s\n",
      "epoch 40 | loss: 0.34237 | train_accuracy: 0.84864 | valid_accuracy: 0.80889 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_accuracy = 0.86\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "clf_partial = TabNetClassifier(\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "    mask_type='entmax'\n",
    ")\n",
    "\n",
    "clf_partial.fit(\n",
    "    X_train=x_train.values, y_train=y_train['gender'].values,\n",
    "    patience=20,\n",
    "    eval_set=[(x_train.values, y_train['gender'].values), (x_valid.values, y_valid['gender'].values)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy'],\n",
    "    from_unsupervised=unsupervised_model,\n",
    "    batch_size=128, virtual_batch_size=64, weights=1, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_pred = clf_partial.predict(x_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8130563798219584"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(tn_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        male       0.87      0.91      0.89       276\n",
      "      female       0.84      0.79      0.81       174\n",
      "\n",
      "    accuracy                           0.86       450\n",
      "   macro avg       0.86      0.85      0.85       450\n",
      "weighted avg       0.86      0.86      0.86       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, tn_pred, target_names=['male', 'female']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
