{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os \n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/work/'\n",
    "np1 = glob.glob(base_dir+'mel_dataset1/*.npy')\n",
    "np2 = glob.glob(base_dir+'mel_dataset2/*.npy')\n",
    "np3 = glob.glob(base_dir+'mel_dataset3/*.npy')\n",
    "np4 = glob.glob(base_dir+'mel_dataset4/*.npy')\n",
    "np5 = glob.glob(base_dir+'mel_dataset5/*.npy')\n",
    "np6 = glob.glob(base_dir+'mel_dataset6/*.npy')\n",
    "np7 = glob.glob(base_dir+'mel_dataset7/*.npy')\n",
    "np8 = glob.glob(base_dir+'mel_dataset8/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np1+np2+np3+np4+np5+np6+np7+np8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('new_train.csv')\n",
    "valid_csv = pd.read_csv('new_valid.csv')\n",
    "all_csv =pd.read_csv('new_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a375fcfc5447cab8986569e33b99d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332e2f30dac540aeba54e1dfca10d490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def npy_list(csv):\n",
    "    npy_list = []\n",
    "    for song_path in tqdm(csv['npy_path']):\n",
    "        song_npy = np.load(song_path).squeeze()\n",
    "        #npy_list.append(song_npy[-1876:])\n",
    "        npy_list.append(song_npy)\n",
    "        \n",
    "    return npy_list\n",
    "\n",
    "train_list = [np.load(song_path).squeeze() for song_path in tqdm(train_csv['npy_path'][:1280])]\n",
    "valid_list = [np.load(song_path).squeeze() for song_path in tqdm(valid_csv['npy_path'][:256])]\n",
    "#train_list = npy_list(train_csv)\n",
    "#valid_list = npy_list(valid_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_list = train_list + valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 1876)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a[:,-1876:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch문 안에 들어가야되나?\n",
    "#train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader: \n",
    "        \n",
    "        \n",
    "        mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        encode, output = model(mel)\n",
    "        \n",
    "        loss = criterion(output, mel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= (len(train_loader))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def val(model, train_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "\n",
    "            encode, output = model(mel)\n",
    "\n",
    "            loss = criterion(output, mel)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= (len(train_loader))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def get_mel_embeding(model, train_loader):\n",
    "    model.eval()\n",
    "    mel_embeding_li = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader: \n",
    "            \n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "            mel_embeding_li.append(encode.detach().cpu().numpy())\n",
    "\n",
    "    return mel_embeding_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ 원래 ##############\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 1876),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.conv7(x)\n",
    "        #print(x.shape)\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "        encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 1876)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.t_conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(512, 512, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(512, 512, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(64, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(64, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(16, 16, kernel_size=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(16, 16, kernel_size=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(8, 8, kernel_size=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(8, 8, kernel_size=1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 1876, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 1876),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(16, 16, kernel_size=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(16, 16, kernel_size=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(32, 32, kernel_size=1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(64, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(64, 64, kernel_size=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(128, 128, kernel_size=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(256, 256, kernel_size=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(512, 512, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv1d(512, 512, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        \n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.conv7(x)\n",
    "        #print(x.shape)\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "        encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 1876)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.t_conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# no dilation\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv7(x)\n",
    "        #print(x.shape)\n",
    "        encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeAutoEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchmetrics\n",
    "#from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "#criterion = MeanAbsolutePercentageError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afe052b20614cdba27ff8685f69232e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 15008]' is invalid for input of size 7681024",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1e68de32d81b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mval_batch_li\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch_li\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_li\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-06c4d428a13e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0ed397bdc264>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mel_spec)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m#encode = self.encoder_fc(x.view(-1, 8 * 7501))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1876\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# print('decode')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 15008]' is invalid for input of size 7681024"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_dir = '/home/work/Tcae_apply/model_dir/'\n",
    "min_loss = 987654321\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 128\n",
    "\n",
    "#train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "    val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "    train_loss = train(model = model, train_loader = train_batch_li) \n",
    "    val_loss = val(model = model, train_loader = val_batch_li) \n",
    "    end = time.time()\n",
    "\n",
    "    print(f'EPOCH:{epoch}, Train Loss:{train_loss}, Val Loss:{val_loss}, 학습 시간: {end - start}')\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        #torch.save(model.state_dict(), model_dir + f'TimeAutoEncoder_val.pt')\n",
    "        #print('모델 저장')\n",
    "        \n",
    "    del train_batch_li\n",
    "    del val_batch_li\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_embeding_li = get_mel_embeding(model = model, train_loader = test_batch_li)\n",
    "#mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(batch_data_dir + 'mel_embeding_val.npy', mel_embeding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
