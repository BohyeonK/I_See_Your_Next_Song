{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os \n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/work/'\n",
    "np1 = glob.glob(base_dir+'mel_dataset1/*.npy')\n",
    "np2 = glob.glob(base_dir+'mel_dataset2/*.npy')\n",
    "np3 = glob.glob(base_dir+'mel_dataset3/*.npy')\n",
    "np4 = glob.glob(base_dir+'mel_dataset4/*.npy')\n",
    "np5 = glob.glob(base_dir+'mel_dataset5/*.npy')\n",
    "np6 = glob.glob(base_dir+'mel_dataset6/*.npy')\n",
    "np7 = glob.glob(base_dir+'mel_dataset7/*.npy')\n",
    "np8 = glob.glob(base_dir+'mel_dataset8/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np1+np2+np3+np4+np5+np6+np7+np8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('new_train.csv')\n",
    "valid_csv = pd.read_csv('new_valid.csv')\n",
    "all_csv =pd.read_csv('new_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3092f31bf7e040dab636d240bad5fa34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f024f7cc91d436c957209be5db78f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def npy_list(csv):\n",
    "    npy_list = []\n",
    "    for song_path in tqdm(csv['npy_path']):\n",
    "        song_npy = np.load(song_path).squeeze()\n",
    "        #npy_list.append(song_npy[-1876:])\n",
    "        npy_list.append(song_npy)\n",
    "        \n",
    "    return npy_list\n",
    "\n",
    "train_list = [np.load(song_path).squeeze() for song_path in tqdm(train_csv['npy_path'])]\n",
    "valid_list = [np.load(song_path).squeeze() for song_path in tqdm(valid_csv['npy_path'])]\n",
    "#train_list = npy_list(train_csv)\n",
    "#valid_list = npy_list(valid_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_list = train_list + valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch문 안에 들어가야되나?\n",
    "#train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader: \n",
    "        \n",
    "        \n",
    "        mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        encode, output = model(mel)\n",
    "        \n",
    "        loss = criterion(output, mel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= (len(train_loader))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def val(model, train_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "\n",
    "            loss = criterion(output, mel)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= (len(train_loader))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def get_mel_embeding(model, train_loader):\n",
    "    model.eval()\n",
    "    mel_embeding_li = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader: \n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "            \n",
    "            mel_embeding_li.append(encode.detach().cpu().numpy())\n",
    "\n",
    "    return mel_embeding_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############ 원래 ##############\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            #nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            #nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            #nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            #nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            #nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 1024, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "        self.concat7_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat6_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat5_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat4_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat3_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat2_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat1_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1024, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x1 = self.conv1(x)\n",
    "        #print(x1.shape)\n",
    "        x = F.pad(x1, pad = (4, 0, 0, 0))\n",
    "        x2 = self.conv2(x)\n",
    "        #print(x2.shape)\n",
    "        x = F.pad(x2, pad = (8, 0, 0, 0))\n",
    "        x3 = self.conv3(x)\n",
    "        #print(x3.shape)\n",
    "        x = F.pad(x3, pad = (16, 0, 0, 0))\n",
    "        x4 = self.conv4(x)\n",
    "        #print(x4.shape)\n",
    "        x = F.pad(x4, pad = (32, 0, 0, 0))\n",
    "        x5 = self.conv5(x)\n",
    "        #print(x5.shape)\n",
    "        x = F.pad(x5, pad = (64, 0, 0, 0))\n",
    "        x6 = self.conv6(x)\n",
    "        #print(x6.shape)\n",
    "        x = F.pad(x6, pad = (128, 0, 0, 0))\n",
    "        x7 = self.conv7(x)\n",
    "        #print(x7.shape)\n",
    "        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        x = torch.cat([x7,x],1) # 4,16,7501\n",
    "        #x = self.concat7_shape(x) \n",
    "        x = F.pad(x, pad = (128, 0, 0, 0)) \n",
    "        x = self.t_conv1(x) # 4,8,7501\n",
    "        #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x6,x],1)\n",
    "        #x = self.concat6_shape(x)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x5,x],1)\n",
    "        #x = self.concat5_shape(x)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x4,x],1)\n",
    "        #x = self.concat4_shape(x)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x3,x],1)\n",
    "        #x = self.concat3_shape(x)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x2,x],1)\n",
    "        #x = self.concat2_shape(x)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x1,x],1)\n",
    "        #x = self.concat1_shape(x)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# no dilation\\n# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\\n# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\\nclass TimeAutoEncoder(nn.Module):\\n    def __init__(self):\\n        super(TimeAutoEncoder, self).__init__()\\n        self.conv1 = nn.Sequential(\\n            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(512),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv2 = nn.Sequential(\\n            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(256),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv3 = nn.Sequential(\\n            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(128),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv4 = nn.Sequential(\\n            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(64),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv5 = nn.Sequential(\\n            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(32),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv6 = nn.Sequential(\\n            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(16),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv7 = nn.Sequential(\\n            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(8),\\n            nn.ReLU(),\\n        )\\n\\n        self.encoder_fc = nn.Sequential(\\n            nn.Linear(8 * 7501, 128),\\n            nn.BatchNorm1d(128),\\n            nn.Tanh(),\\n        )\\n        \\n        self.decoder_fc = nn.Sequential(\\n            nn.Linear(128, 8 * 7501),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv1 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\\n            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(16),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv2 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\\n            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(32),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv3 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\\n            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(64),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv4 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\\n            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(128),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv5 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\\n            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(256),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv6 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\\n            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(512),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv7 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\\n            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\\n        )\\n\\n    def forward(self, mel_spec):\\n        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\\n        x = self.conv1(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.conv2(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.conv3(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.conv4(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.conv5(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.conv6(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.conv7(x)\\n        #print(x.shape)\\n        encode = self.encoder_fc(x.view(-1, 8 * 7501))\\n\\n        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\\n\\n        # print('decode')\\n        x = self.decoder_fc(encode)\\n        x = x.view(-1, 8, 7501)\\n        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv1(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv2(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv3(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv4(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv5(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv6(x)\\n        #print(x.shape)\\n        x = F.pad(x, pad = (2, 0, 0, 0))\\n        x = self.t_conv7(x)\\n        #print(x.shape)\\n        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\\n        \\n        return encode, x\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# no dilation\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.conv7(x)\n",
    "        #print(x.shape)\n",
    "        encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# skip connection\\n# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\\n# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\\nclass TimeAutoEncoder(nn.Module):\\n    def __init__(self):\\n        super(TimeAutoEncoder, self).__init__()\\n        self.conv1 = nn.Sequential(\\n            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(512),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv2 = nn.Sequential(\\n            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\\n            nn.BatchNorm1d(256),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv3 = nn.Sequential(\\n            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\\n            nn.BatchNorm1d(128),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv4 = nn.Sequential(\\n            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\\n            nn.BatchNorm1d(64),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv5 = nn.Sequential(\\n            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\\n            nn.BatchNorm1d(32),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv6 = nn.Sequential(\\n            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\\n            nn.BatchNorm1d(16),\\n            nn.ReLU(),\\n        )\\n\\n        self.conv7 = nn.Sequential(\\n            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\\n            nn.BatchNorm1d(8),\\n            nn.ReLU(),\\n        )\\n\\n        self.encoder_fc = nn.Sequential(\\n            nn.Linear(8 * 7501, 128),\\n            nn.BatchNorm1d(128),\\n            nn.Tanh(),\\n        )\\n        \\n        self.decoder_fc = nn.Sequential(\\n            nn.Linear(128, 8 * 7501),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv1 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\\n            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\\n            nn.BatchNorm1d(16),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv2 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\\n            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\\n            nn.BatchNorm1d(32),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv3 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\\n            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\\n            nn.BatchNorm1d(64),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv4 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\\n            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\\n            nn.BatchNorm1d(128),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv5 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\\n            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\\n            nn.BatchNorm1d(256),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv6 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\\n            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\\n            nn.BatchNorm1d(512),\\n            nn.ReLU(),\\n        )\\n\\n        self.t_conv7 = nn.Sequential(\\n            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\\n            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\\n        )\\n\\n        self.concat7_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(8),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        self.concat6_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(16),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        self.concat5_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(32),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        self.concat4_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(64),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        self.concat3_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(128),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        self.concat2_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(256),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        self.concat1_shape = nn.Sequential(\\n            nn.Conv1d(in_channels = 1024, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\\n            nn.BatchNorm1d(512),\\n            nn.ReLU(),\\n            \\n        )\\n        \\n        \\n    def forward(self, mel_spec):\\n        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\\n        x1 = self.conv1(x)\\n        #print(x1.shape)\\n        x = F.pad(x1, pad = (4, 0, 0, 0))\\n        x2 = self.conv2(x)\\n        #print(x2.shape)\\n        x = F.pad(x2, pad = (8, 0, 0, 0))\\n        x3 = self.conv3(x)\\n        #print(x3.shape)\\n        x = F.pad(x3, pad = (16, 0, 0, 0))\\n        x4 = self.conv4(x)\\n        #print(x4.shape)\\n        x = F.pad(x4, pad = (32, 0, 0, 0))\\n        x5 = self.conv5(x)\\n        #print(x5.shape)\\n        x = F.pad(x5, pad = (64, 0, 0, 0))\\n        x6 = self.conv6(x)\\n        #print(x6.shape)\\n        x = F.pad(x6, pad = (128, 0, 0, 0))\\n        x7 = self.conv7(x)\\n        #print(x7.shape)\\n        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\\n\\n        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\\n\\n        # print('decode')\\n        x = self.decoder_fc(encode)\\n        x = x.view(-1, 8, 7501)\\n        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\\n        \\n        x = torch.cat([x7,x],1) # 4,16,7501\\n        x = self.concat7_shape(x) \\n        x = F.pad(x, pad = (130, 0, 0, 0)) \\n        x = self.t_conv1(x) # 4,8,7501\\n        #print(x.shape,'new_cat7')\\n        \\n        \\n        x = torch.cat([x6,x],1)\\n        x = self.concat6_shape(x)\\n        x = F.pad(x, pad = (66, 0, 0, 0))\\n        x = self.t_conv2(x)\\n        \\n        \\n        x = torch.cat([x5,x],1)\\n        x = self.concat5_shape(x)\\n        x = F.pad(x, pad = (34, 0, 0, 0))\\n        x = self.t_conv3(x)\\n        \\n        \\n        \\n        x = torch.cat([x4,x],1)\\n        x = self.concat4_shape(x)\\n        x = F.pad(x, pad = (18, 0, 0, 0))\\n        x = self.t_conv4(x)\\n        \\n        \\n        x = torch.cat([x3,x],1)\\n        x = self.concat3_shape(x)\\n        x = F.pad(x, pad = (10, 0, 0, 0))\\n        x = self.t_conv5(x)\\n        \\n        \\n        \\n        x = torch.cat([x2,x],1)\\n        x = self.concat2_shape(x)\\n        x = F.pad(x, pad = (6, 0, 0, 0))\\n        x = self.t_conv6(x)\\n        \\n        \\n        \\n        x = torch.cat([x1,x],1)\\n        x = self.concat1_shape(x)\\n        x = F.pad(x, pad = (4, 0, 0, 0))\\n        x = self.t_conv7(x)\\n    \\n        \\n        #print(x.shape)\\n        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\\n        \\n        return encode, x\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# skip connection\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "        self.concat7_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat6_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat5_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat4_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat3_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat2_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.concat1_shape = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1024, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x1 = self.conv1(x)\n",
    "        #print(x1.shape)\n",
    "        x = F.pad(x1, pad = (4, 0, 0, 0))\n",
    "        x2 = self.conv2(x)\n",
    "        #print(x2.shape)\n",
    "        x = F.pad(x2, pad = (8, 0, 0, 0))\n",
    "        x3 = self.conv3(x)\n",
    "        #print(x3.shape)\n",
    "        x = F.pad(x3, pad = (16, 0, 0, 0))\n",
    "        x4 = self.conv4(x)\n",
    "        #print(x4.shape)\n",
    "        x = F.pad(x4, pad = (32, 0, 0, 0))\n",
    "        x5 = self.conv5(x)\n",
    "        #print(x5.shape)\n",
    "        x = F.pad(x5, pad = (64, 0, 0, 0))\n",
    "        x6 = self.conv6(x)\n",
    "        #print(x6.shape)\n",
    "        x = F.pad(x6, pad = (128, 0, 0, 0))\n",
    "        x7 = self.conv7(x)\n",
    "        #print(x7.shape)\n",
    "        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        x = torch.cat([x7,x],1) # 4,16,7501\n",
    "        x = self.concat7_shape(x) \n",
    "        x = F.pad(x, pad = (130, 0, 0, 0)) \n",
    "        x = self.t_conv1(x) # 4,8,7501\n",
    "        #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x6,x],1)\n",
    "        x = self.concat6_shape(x)\n",
    "        x = F.pad(x, pad = (66, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x5,x],1)\n",
    "        x = self.concat5_shape(x)\n",
    "        x = F.pad(x, pad = (34, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x4,x],1)\n",
    "        x = self.concat4_shape(x)\n",
    "        x = F.pad(x, pad = (18, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x3,x],1)\n",
    "        x = self.concat3_shape(x)\n",
    "        x = F.pad(x, pad = (10, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x2,x],1)\n",
    "        x = self.concat2_shape(x)\n",
    "        x = F.pad(x, pad = (6, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x1,x],1)\n",
    "        x = self.concat1_shape(x)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "    \n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeAutoEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchmetrics\n",
    "#from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "#criterion = MeanAbsolutePercentageError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7563460ebe9443668670bc687f6bb96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1, Train Loss:147529.8782110699, Val Loss:15281.2935546875, 학습 시간: 81.71810507774353\n",
      "모델 저장\n",
      "EPOCH:2, Train Loss:10662.40383342161, Val Loss:5051.080322265625, 학습 시간: 32.199466705322266\n",
      "모델 저장\n",
      "EPOCH:3, Train Loss:3710.6201958090573, Val Loss:2342.2825317382812, 학습 시간: 26.571794033050537\n",
      "모델 저장\n",
      "EPOCH:4, Train Loss:2031.1439271054026, Val Loss:1485.2213256835937, 학습 시간: 26.208123445510864\n",
      "모델 저장\n",
      "EPOCH:5, Train Loss:1347.0279706534693, Val Loss:1096.1991455078125, 학습 시간: 26.76035237312317\n",
      "모델 저장\n",
      "EPOCH:6, Train Loss:1031.0193729723915, Val Loss:989.2414001464844, 학습 시간: 26.018693447113037\n",
      "모델 저장\n",
      "EPOCH:7, Train Loss:944.8359095686573, Val Loss:743.947802734375, 학습 시간: 26.34234070777893\n",
      "모델 저장\n",
      "EPOCH:8, Train Loss:694.6019990565413, Val Loss:609.6730773925781, 학습 시간: 26.398714065551758\n",
      "모델 저장\n",
      "EPOCH:9, Train Loss:595.6984164997683, Val Loss:529.0238616943359, 학습 시간: 25.81749153137207\n",
      "모델 저장\n",
      "EPOCH:10, Train Loss:663.3840906175517, Val Loss:702.9898498535156, 학습 시간: 26.375518321990967\n",
      "EPOCH:11, Train Loss:539.1289983199814, Val Loss:412.85716552734374, 학습 시간: 26.41797423362732\n",
      "모델 저장\n",
      "EPOCH:12, Train Loss:409.2794686010328, Val Loss:375.7756774902344, 학습 시간: 25.778136730194092\n",
      "모델 저장\n",
      "EPOCH:13, Train Loss:383.1753152103747, Val Loss:349.13360290527345, 학습 시간: 26.136838674545288\n",
      "모델 저장\n",
      "EPOCH:14, Train Loss:351.2519308833753, Val Loss:328.4095932006836, 학습 시간: 26.274900197982788\n",
      "모델 저장\n",
      "EPOCH:15, Train Loss:340.1564475883872, Val Loss:365.6415740966797, 학습 시간: 26.177032470703125\n",
      "EPOCH:16, Train Loss:310.5561577748444, Val Loss:285.8792419433594, 학습 시간: 25.735201597213745\n",
      "모델 저장\n",
      "EPOCH:17, Train Loss:300.27015272237486, Val Loss:271.49830322265626, 학습 시간: 25.86911392211914\n",
      "모델 저장\n",
      "EPOCH:18, Train Loss:330.20797005346265, Val Loss:275.8112365722656, 학습 시간: 26.110076189041138\n",
      "EPOCH:19, Train Loss:271.95274715100305, Val Loss:242.6286392211914, 학습 시간: 26.134477615356445\n",
      "모델 저장\n",
      "EPOCH:20, Train Loss:241.3137093236891, Val Loss:197.03339233398438, 학습 시간: 26.271756410598755\n",
      "모델 저장\n",
      "EPOCH:21, Train Loss:200.18415004924194, Val Loss:203.03565979003906, 학습 시간: 25.764471530914307\n",
      "EPOCH:22, Train Loss:392.04799302957827, Val Loss:281.52671203613284, 학습 시간: 25.803649187088013\n",
      "EPOCH:23, Train Loss:211.96386369608217, Val Loss:172.4850814819336, 학습 시간: 25.893646955490112\n",
      "모델 저장\n",
      "EPOCH:24, Train Loss:163.200830879858, Val Loss:160.15254745483398, 학습 시간: 25.974618196487427\n",
      "모델 저장\n",
      "EPOCH:25, Train Loss:162.38766233799822, Val Loss:144.29875717163085, 학습 시간: 25.77160358428955\n",
      "모델 저장\n",
      "EPOCH:26, Train Loss:150.5721056663384, Val Loss:151.28722534179687, 학습 시간: 25.97131848335266\n",
      "EPOCH:27, Train Loss:153.37545866885426, Val Loss:140.10958862304688, 학습 시간: 26.12879991531372\n",
      "모델 저장\n",
      "EPOCH:28, Train Loss:157.61801768157443, Val Loss:139.63656463623047, 학습 시간: 25.9369695186615\n",
      "모델 저장\n",
      "EPOCH:29, Train Loss:136.0414773973368, Val Loss:149.33834533691407, 학습 시간: 25.68220806121826\n",
      "EPOCH:30, Train Loss:144.14672657594843, Val Loss:144.09572067260743, 학습 시간: 25.71068811416626\n",
      "EPOCH:31, Train Loss:140.66402008573888, Val Loss:189.0670150756836, 학습 시간: 25.6957049369812\n",
      "EPOCH:32, Train Loss:157.70447501489673, Val Loss:158.64530181884766, 학습 시간: 25.825539112091064\n",
      "EPOCH:33, Train Loss:129.13956735901914, Val Loss:102.32549514770508, 학습 시간: 25.92884087562561\n",
      "모델 저장\n",
      "EPOCH:34, Train Loss:108.48312636553231, Val Loss:102.04055709838867, 학습 시간: 26.052579879760742\n",
      "모델 저장\n",
      "EPOCH:35, Train Loss:174.396467952405, Val Loss:149.66781921386718, 학습 시간: 25.9976167678833\n",
      "EPOCH:36, Train Loss:140.81535416942532, Val Loss:115.33159408569335, 학습 시간: 25.983656883239746\n",
      "EPOCH:37, Train Loss:126.53589953406383, Val Loss:144.07838592529296, 학습 시간: 26.102222442626953\n",
      "EPOCH:38, Train Loss:130.26076572224244, Val Loss:94.63564529418946, 학습 시간: 25.878990650177002\n",
      "모델 저장\n",
      "EPOCH:39, Train Loss:91.87021591703771, Val Loss:70.66024208068848, 학습 시간: 25.777798175811768\n",
      "모델 저장\n",
      "EPOCH:40, Train Loss:115.8588652529959, Val Loss:117.74953689575196, 학습 시간: 25.776964902877808\n",
      "EPOCH:41, Train Loss:107.69898689399331, Val Loss:86.93202896118164, 학습 시간: 25.761528730392456\n",
      "EPOCH:42, Train Loss:84.65514528953423, Val Loss:69.5665771484375, 학습 시간: 25.849675178527832\n",
      "모델 저장\n",
      "EPOCH:43, Train Loss:74.77013636443574, Val Loss:83.35256004333496, 학습 시간: 25.893150091171265\n",
      "EPOCH:44, Train Loss:80.58912775072001, Val Loss:124.3499382019043, 학습 시간: 25.919561624526978\n",
      "EPOCH:45, Train Loss:109.89197430368198, Val Loss:69.14462547302246, 학습 시간: 25.92061948776245\n",
      "모델 저장\n",
      "EPOCH:46, Train Loss:92.15986471661067, Val Loss:77.6717658996582, 학습 시간: 25.91660237312317\n",
      "EPOCH:47, Train Loss:85.08046735343287, Val Loss:88.21369514465331, 학습 시간: 25.8496572971344\n",
      "EPOCH:48, Train Loss:79.67251936055847, Val Loss:111.3170555114746, 학습 시간: 25.93182373046875\n",
      "EPOCH:49, Train Loss:79.37672185089629, Val Loss:61.050479125976565, 학습 시간: 25.957074642181396\n",
      "모델 저장\n",
      "EPOCH:50, Train Loss:71.1719527163748, Val Loss:80.51362228393555, 학습 시간: 25.932133436203003\n",
      "EPOCH:51, Train Loss:68.51285740480584, Val Loss:62.35720710754394, 학습 시간: 25.78822636604309\n",
      "EPOCH:52, Train Loss:68.72072588387182, Val Loss:105.43078308105468, 학습 시간: 25.789061546325684\n",
      "EPOCH:53, Train Loss:77.27873281705178, Val Loss:55.79406051635742, 학습 시간: 25.76310157775879\n",
      "모델 저장\n",
      "EPOCH:54, Train Loss:56.309952234817764, Val Loss:47.057560729980466, 학습 시간: 25.74631977081299\n",
      "모델 저장\n",
      "EPOCH:55, Train Loss:64.38579973123841, Val Loss:56.94366645812988, 학습 시간: 25.703041791915894\n",
      "EPOCH:56, Train Loss:64.14209236532955, Val Loss:79.40087242126465, 학습 시간: 25.777127981185913\n",
      "EPOCH:57, Train Loss:72.59341146178164, Val Loss:87.63355865478516, 학습 시간: 25.801355838775635\n",
      "EPOCH:58, Train Loss:77.50742184913764, Val Loss:55.069083786010744, 학습 시간: 25.904606819152832\n",
      "EPOCH:59, Train Loss:78.91960519047107, Val Loss:58.32065315246582, 학습 시간: 25.91104483604431\n",
      "EPOCH:60, Train Loss:72.53025313555185, Val Loss:50.57897872924805, 학습 시간: 25.895418643951416\n",
      "EPOCH:61, Train Loss:61.12714618747517, Val Loss:46.26704216003418, 학습 시간: 25.934496641159058\n",
      "모델 저장\n",
      "EPOCH:62, Train Loss:53.71888231827041, Val Loss:68.84674453735352, 학습 시간: 25.891159057617188\n",
      "EPOCH:63, Train Loss:60.56881694470422, Val Loss:61.27181282043457, 학습 시간: 25.883848428726196\n",
      "EPOCH:64, Train Loss:57.92350859561209, Val Loss:41.67104949951172, 학습 시간: 25.938063859939575\n",
      "모델 저장\n",
      "EPOCH:65, Train Loss:50.494830826581534, Val Loss:70.92433013916016, 학습 시간: 25.928190231323242\n",
      "EPOCH:66, Train Loss:49.91771335925086, Val Loss:45.368651962280275, 학습 시간: 25.96715259552002\n",
      "EPOCH:67, Train Loss:48.793434337034064, Val Loss:35.47544136047363, 학습 시간: 25.956058740615845\n",
      "모델 저장\n",
      "EPOCH:68, Train Loss:42.95170958567474, Val Loss:48.29244804382324, 학습 시간: 25.7432541847229\n",
      "EPOCH:69, Train Loss:59.07264285976604, Val Loss:60.77660064697265, 학습 시간: 25.763381481170654\n",
      "EPOCH:70, Train Loss:55.24120130377301, Val Loss:48.7687068939209, 학습 시간: 25.772719860076904\n",
      "EPOCH:71, Train Loss:41.307386818578685, Val Loss:32.12161560058594, 학습 시간: 25.76594638824463\n",
      "모델 저장\n",
      "EPOCH:72, Train Loss:43.65987043865656, Val Loss:52.790487670898436, 학습 시간: 25.755266189575195\n",
      "EPOCH:73, Train Loss:59.23139743481652, Val Loss:76.4475227355957, 학습 시간: 25.744312524795532\n",
      "EPOCH:74, Train Loss:61.72649587210962, Val Loss:39.92181396484375, 학습 시간: 25.74832010269165\n",
      "EPOCH:75, Train Loss:42.64282291218386, Val Loss:33.668740844726564, 학습 시간: 25.778213024139404\n",
      "EPOCH:76, Train Loss:44.24725031448623, Val Loss:45.11315574645996, 학습 시간: 25.878750324249268\n",
      "EPOCH:77, Train Loss:42.223661713680976, Val Loss:50.95110321044922, 학습 시간: 25.941179752349854\n",
      "EPOCH:78, Train Loss:37.20329397815769, Val Loss:36.14168567657471, 학습 시간: 25.900076627731323\n",
      "EPOCH:79, Train Loss:37.43766435526185, Val Loss:48.0234977722168, 학습 시간: 25.913570404052734\n",
      "EPOCH:80, Train Loss:34.76433863882291, Val Loss:54.82677040100098, 학습 시간: 25.86315369606018\n",
      "EPOCH:81, Train Loss:57.82664631989043, Val Loss:32.18454875946045, 학습 시간: 25.894306182861328\n",
      "EPOCH:82, Train Loss:32.84275200407384, Val Loss:34.016530418395995, 학습 시간: 25.900980472564697\n",
      "EPOCH:83, Train Loss:38.04316391379146, Val Loss:25.759695053100586, 학습 시간: 25.927717447280884\n",
      "모델 저장\n",
      "EPOCH:84, Train Loss:39.07017824205302, Val Loss:25.932010841369628, 학습 시간: 25.850981950759888\n",
      "EPOCH:85, Train Loss:51.62654527567201, Val Loss:39.16476306915283, 학습 시간: 25.834916353225708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:86, Train Loss:63.71654853174242, Val Loss:73.27498092651368, 학습 시간: 25.833107233047485\n",
      "EPOCH:87, Train Loss:58.52097540386652, Val Loss:37.254844665527344, 학습 시간: 25.87941551208496\n",
      "EPOCH:88, Train Loss:34.00888164972855, Val Loss:34.54324836730957, 학습 시간: 25.918862104415894\n",
      "EPOCH:89, Train Loss:43.75223127462096, Val Loss:48.19899291992188, 학습 시간: 25.84086513519287\n",
      "EPOCH:90, Train Loss:39.536511308055815, Val Loss:41.66391315460205, 학습 시간: 25.83341073989868\n",
      "EPOCH:91, Train Loss:39.7438505463681, Val Loss:42.51291027069092, 학습 시간: 25.825258016586304\n",
      "EPOCH:92, Train Loss:32.36233151969263, Val Loss:30.449234580993654, 학습 시간: 25.816336393356323\n",
      "EPOCH:93, Train Loss:25.936863769919185, Val Loss:23.198488235473633, 학습 시간: 25.79295778274536\n",
      "모델 저장\n",
      "EPOCH:94, Train Loss:33.453416113126075, Val Loss:21.28130226135254, 학습 시간: 25.73160433769226\n",
      "모델 저장\n",
      "EPOCH:95, Train Loss:25.29815187292584, Val Loss:22.12858352661133, 학습 시간: 25.72589111328125\n",
      "EPOCH:96, Train Loss:21.77077626373808, Val Loss:28.881373596191406, 학습 시간: 25.689974784851074\n",
      "EPOCH:97, Train Loss:42.63770394406076, Val Loss:42.98658485412598, 학습 시간: 25.742432832717896\n",
      "EPOCH:98, Train Loss:36.14826338169939, Val Loss:20.941265678405763, 학습 시간: 25.819652795791626\n",
      "모델 저장\n",
      "EPOCH:99, Train Loss:31.122448678744043, Val Loss:29.295202255249023, 학습 시간: 25.842161178588867\n",
      "EPOCH:100, Train Loss:25.63466794612044, Val Loss:27.275857543945314, 학습 시간: 25.829066514968872\n",
      "EPOCH:101, Train Loss:24.68388436204296, Val Loss:20.517164325714113, 학습 시간: 25.817302703857422\n",
      "모델 저장\n",
      "EPOCH:102, Train Loss:36.149464429435085, Val Loss:29.885690689086914, 학습 시간: 25.839171648025513\n",
      "EPOCH:103, Train Loss:29.478851027407888, Val Loss:28.873258209228517, 학습 시간: 25.817260265350342\n",
      "EPOCH:104, Train Loss:32.504805581044344, Val Loss:24.024935150146483, 학습 시간: 25.84042716026306\n",
      "EPOCH:105, Train Loss:32.11407422211211, Val Loss:31.196886444091795, 학습 시간: 25.826412439346313\n",
      "EPOCH:106, Train Loss:41.89524773419914, Val Loss:40.89980049133301, 학습 시간: 25.876766204833984\n",
      "EPOCH:107, Train Loss:24.970709590588587, Val Loss:14.996740436553955, 학습 시간: 25.869548797607422\n",
      "모델 저장\n",
      "EPOCH:108, Train Loss:28.49181632672326, Val Loss:53.22361106872559, 학습 시간: 25.844085931777954\n",
      "EPOCH:109, Train Loss:48.371180259575276, Val Loss:28.286021614074706, 학습 시간: 25.815927982330322\n",
      "EPOCH:110, Train Loss:23.89795807660636, Val Loss:25.643425750732423, 학습 시간: 25.890005826950073\n",
      "EPOCH:111, Train Loss:33.73455839642023, Val Loss:26.598262214660643, 학습 시간: 25.883952140808105\n",
      "EPOCH:112, Train Loss:23.439141790745623, Val Loss:22.05087833404541, 학습 시간: 25.840359687805176\n",
      "EPOCH:113, Train Loss:27.779180946996657, Val Loss:27.023025894165038, 학습 시간: 25.790666580200195\n",
      "EPOCH:114, Train Loss:27.473649881653866, Val Loss:21.004961204528808, 학습 시간: 25.755980014801025\n",
      "EPOCH:115, Train Loss:24.39188751931918, Val Loss:32.63896026611328, 학습 시간: 25.778695344924927\n",
      "EPOCH:116, Train Loss:26.47173787779727, Val Loss:18.108601760864257, 학습 시간: 25.76419472694397\n",
      "EPOCH:117, Train Loss:35.94491687063444, Val Loss:35.770073127746585, 학습 시간: 25.764482021331787\n",
      "EPOCH:118, Train Loss:20.44135098538156, Val Loss:15.728365898132324, 학습 시간: 25.725147008895874\n",
      "EPOCH:119, Train Loss:40.515562122151, Val Loss:31.991308784484865, 학습 시간: 25.734468936920166\n",
      "EPOCH:120, Train Loss:41.250865596835894, Val Loss:44.20980110168457, 학습 시간: 25.740267753601074\n",
      "EPOCH:121, Train Loss:31.324773966255833, Val Loss:49.92627182006836, 학습 시간: 25.7602858543396\n",
      "EPOCH:122, Train Loss:39.55029507006629, Val Loss:25.372347831726074, 학습 시간: 25.781792640686035\n",
      "EPOCH:123, Train Loss:29.159216056435795, Val Loss:25.81398582458496, 학습 시간: 25.773751497268677\n",
      "EPOCH:124, Train Loss:34.13381177287991, Val Loss:17.410699462890626, 학습 시간: 25.84611678123474\n",
      "EPOCH:125, Train Loss:15.083293138924292, Val Loss:22.689048957824706, 학습 시간: 25.819183588027954\n",
      "EPOCH:126, Train Loss:21.806596610505704, Val Loss:35.82046241760254, 학습 시간: 25.848378896713257\n",
      "EPOCH:127, Train Loss:33.770134570234916, Val Loss:36.998853302001955, 학습 시간: 25.86165976524353\n",
      "EPOCH:128, Train Loss:45.63722038269043, Val Loss:81.70081329345703, 학습 시간: 25.881866455078125\n",
      "EPOCH:129, Train Loss:41.01334232394978, Val Loss:23.47790870666504, 학습 시간: 25.830045223236084\n",
      "EPOCH:130, Train Loss:31.370560759204928, Val Loss:33.97893314361572, 학습 시간: 25.83616876602173\n",
      "EPOCH:131, Train Loss:30.179988392328813, Val Loss:18.446350193023683, 학습 시간: 25.821791172027588\n",
      "EPOCH:132, Train Loss:17.441908804036803, Val Loss:14.502026081085205, 학습 시간: 25.82339644432068\n",
      "모델 저장\n",
      "EPOCH:133, Train Loss:22.46656223879022, Val Loss:24.18262004852295, 학습 시간: 25.777801752090454\n",
      "EPOCH:134, Train Loss:18.767866829694327, Val Loss:11.328938913345336, 학습 시간: 25.857065200805664\n",
      "모델 저장\n",
      "EPOCH:135, Train Loss:26.12438762794107, Val Loss:16.807688331604005, 학습 시간: 25.82068371772766\n",
      "EPOCH:136, Train Loss:21.753589387667382, Val Loss:35.58428382873535, 학습 시간: 25.83717107772827\n",
      "EPOCH:137, Train Loss:21.53968864376262, Val Loss:16.617810821533205, 학습 시간: 25.824157238006592\n",
      "EPOCH:138, Train Loss:14.540980484526036, Val Loss:14.566039943695069, 학습 시간: 25.87977933883667\n",
      "EPOCH:139, Train Loss:24.838010448520468, Val Loss:16.074404621124266, 학습 시간: 25.7892644405365\n",
      "EPOCH:140, Train Loss:19.705047639749818, Val Loss:22.609202194213868, 학습 시간: 25.818660020828247\n",
      "EPOCH:141, Train Loss:23.83017832545911, Val Loss:20.297830009460448, 학습 시간: 25.787007093429565\n",
      "EPOCH:142, Train Loss:26.590195979102184, Val Loss:24.661289024353028, 학습 시간: 25.770567417144775\n",
      "EPOCH:143, Train Loss:16.504376096240545, Val Loss:22.80158386230469, 학습 시간: 25.79284691810608\n",
      "EPOCH:144, Train Loss:17.349795179851984, Val Loss:15.061473083496093, 학습 시간: 25.800013065338135\n",
      "EPOCH:145, Train Loss:19.302675376504155, Val Loss:13.697455501556396, 학습 시간: 25.826378107070923\n",
      "EPOCH:146, Train Loss:19.086124436329985, Val Loss:21.852775478363036, 학습 시간: 25.838886499404907\n",
      "EPOCH:147, Train Loss:25.483684361991237, Val Loss:20.586879158020018, 학습 시간: 25.80264186859131\n",
      "EPOCH:148, Train Loss:25.711703171164302, Val Loss:20.337192630767824, 학습 시간: 25.78221845626831\n",
      "EPOCH:149, Train Loss:22.24665787260411, Val Loss:13.208956432342529, 학습 시간: 25.785522937774658\n",
      "EPOCH:150, Train Loss:14.318521693601447, Val Loss:10.896590518951417, 학습 시간: 25.805094480514526\n",
      "모델 저장\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_dir = '/home/work/Tcae_apply/model_dir3/'\n",
    "min_loss = 987654321\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "#tloss_list=[]\n",
    "#vloss_list=[]\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    train_loss = train(model = model, train_loader = train_batch_li) \n",
    "    val_loss = val(model = model, train_loader = val_batch_li) \n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    #tloss_list.append(train_loss)\n",
    "    #vloss_list.append(val_loss)\n",
    "    \n",
    "    print(f'EPOCH:{epoch}, Train Loss:{train_loss}, Val Loss:{val_loss}, 학습 시간: {end - start}')\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_dir + f'TimeAutoEncoder_skipconnection_val.pt')\n",
    "        print('모델 저장')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_embeding_li = get_mel_embeding(model = model, train_loader = test_batch_li)\n",
    "#mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(batch_data_dir + 'mel_embeding_val.npy', mel_embeding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
