{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os \n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/work/'\n",
    "np1 = glob.glob(base_dir+'mel_dataset1/*.npy')\n",
    "np2 = glob.glob(base_dir+'mel_dataset2/*.npy')\n",
    "np3 = glob.glob(base_dir+'mel_dataset3/*.npy')\n",
    "np4 = glob.glob(base_dir+'mel_dataset4/*.npy')\n",
    "np5 = glob.glob(base_dir+'mel_dataset5/*.npy')\n",
    "np6 = glob.glob(base_dir+'mel_dataset6/*.npy')\n",
    "np7 = glob.glob(base_dir+'mel_dataset7/*.npy')\n",
    "np8 = glob.glob(base_dir+'mel_dataset8/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np1+np2+np3+np4+np5+np6+np7+np8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('new_train.csv')\n",
    "valid_csv = pd.read_csv('new_valid.csv')\n",
    "all_csv =pd.read_csv('new_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8a0a27a91e40688c4d7662c5aa17e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b6bc9ea03549f5a9fab9269f8131e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def npy_list(csv):\n",
    "    npy_list = []\n",
    "    for song_path in tqdm(csv['npy_path']):\n",
    "        song_npy = np.load(song_path).squeeze()\n",
    "        #npy_list.append(song_npy[-1876:])\n",
    "        npy_list.append(song_npy)\n",
    "        \n",
    "    return npy_list\n",
    "\n",
    "train_list = [np.load(song_path).squeeze() for song_path in tqdm(train_csv['npy_path'])]\n",
    "valid_list = [np.load(song_path).squeeze() for song_path in tqdm(valid_csv['npy_path'])]\n",
    "#train_list = npy_list(train_csv)\n",
    "#valid_list = npy_list(valid_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_list = train_list + valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch문 안에 들어가야되나?\n",
    "#train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise encoding\n",
    "def add_noise(data):\n",
    "    noise = torch.randn(data.size()) * 0.2 \n",
    "    # 무작위 작음은 torch.randn() 함수로 만들고 img.size()를 넣어 이미지와 같은 크기의 잡음을 만듭니다.\n",
    "    # 잡음의 강도는 임의로 0.2로 정했습니다.\n",
    "    noisy_data = data + noise\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "#         batch = add_noise(batch) # denoise encoding\n",
    "        mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        encode, output = model(mel)\n",
    "        \n",
    "        loss = criterion(output, mel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= (len(train_loader))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def val(model, train_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "\n",
    "            loss = criterion(output, mel)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= (len(train_loader))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def get_mel_embeding(model, train_loader):\n",
    "    model.eval()\n",
    "    mel_embeding_li = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader: \n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "            \n",
    "            mel_embeding_li.append(encode.detach().cpu().numpy())\n",
    "\n",
    "    return mel_embeding_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 원래 ##############\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 1024, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x1 = self.conv1(x)\n",
    "        #print(x1.shape)\n",
    "        x = F.pad(x1, pad = (4, 0, 0, 0))\n",
    "        x2 = self.conv2(x)\n",
    "        #print(x2.shape)\n",
    "        x = F.pad(x2, pad = (8, 0, 0, 0))\n",
    "        x3 = self.conv3(x)\n",
    "        #print(x3.shape)\n",
    "        x = F.pad(x3, pad = (16, 0, 0, 0))\n",
    "        x4 = self.conv4(x)\n",
    "        #print(x4.shape)\n",
    "        x = F.pad(x4, pad = (32, 0, 0, 0))\n",
    "        x5 = self.conv5(x)\n",
    "        #print(x5.shape)\n",
    "        x = F.pad(x5, pad = (64, 0, 0, 0))\n",
    "        x6 = self.conv6(x)\n",
    "        #print(x6.shape)\n",
    "        x = F.pad(x6, pad = (128, 0, 0, 0))\n",
    "        x7 = self.conv7(x)\n",
    "        #print(x7.shape)\n",
    "        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        x = torch.cat([x7,x],1) # 4,16,7501\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0)) \n",
    "        x = self.t_conv1(x) # 4,8,7501\n",
    "        #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x6,x],1)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x5,x],1)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x4,x],1)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x3,x],1)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x2,x],1)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x1,x],1)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no dilation\n",
    "# # encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# # decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "# class TimeAutoEncoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TimeAutoEncoder, self).__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv4 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv5 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv6 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv7 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.encoder_fc = nn.Sequential(\n",
    "#             nn.Linear(8 * 7501, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder_fc = nn.Sequential(\n",
    "#             nn.Linear(128, 8 * 7501),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv1 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "#             nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv2 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv3 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv4 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv5 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv6 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv7 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, mel_spec):\n",
    "#         x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv1(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv2(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv3(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv4(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv5(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv6(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv7(x)\n",
    "#         #print(x.shape)\n",
    "#         encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "#         #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "#         # print('decode')\n",
    "#         x = self.decoder_fc(encode)\n",
    "#         x = x.view(-1, 8, 7501)\n",
    "#         x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv1(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv2(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv3(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv4(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv5(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv6(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv7(x)\n",
    "#         #print(x.shape)\n",
    "#         x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "#         return encode, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # skip connection\n",
    "# # encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# # decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "# class TimeAutoEncoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TimeAutoEncoder, self).__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv4 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv5 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv6 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv7 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.encoder_fc = nn.Sequential(\n",
    "#             nn.Linear(8 * 7501, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder_fc = nn.Sequential(\n",
    "#             nn.Linear(128, 8 * 7501),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv1 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "#             nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv2 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv3 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv4 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv5 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv6 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv7 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "#         )\n",
    "\n",
    "#         self.concat7_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat6_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat5_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat4_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat3_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat2_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat1_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 1024, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     def forward(self, mel_spec):\n",
    "#         x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "#         x1 = self.conv1(x)\n",
    "#         #print(x1.shape)\n",
    "#         x = F.pad(x1, pad = (4, 0, 0, 0))\n",
    "#         x2 = self.conv2(x)\n",
    "#         #print(x2.shape)\n",
    "#         x = F.pad(x2, pad = (8, 0, 0, 0))\n",
    "#         x3 = self.conv3(x)\n",
    "#         #print(x3.shape)\n",
    "#         x = F.pad(x3, pad = (16, 0, 0, 0))\n",
    "#         x4 = self.conv4(x)\n",
    "#         #print(x4.shape)\n",
    "#         x = F.pad(x4, pad = (32, 0, 0, 0))\n",
    "#         x5 = self.conv5(x)\n",
    "#         #print(x5.shape)\n",
    "#         x = F.pad(x5, pad = (64, 0, 0, 0))\n",
    "#         x6 = self.conv6(x)\n",
    "#         #print(x6.shape)\n",
    "#         x = F.pad(x6, pad = (128, 0, 0, 0))\n",
    "#         x7 = self.conv7(x)\n",
    "#         #print(x7.shape)\n",
    "#         encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "#         #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "#         # print('decode')\n",
    "#         x = self.decoder_fc(encode)\n",
    "#         x = x.view(-1, 8, 7501)\n",
    "#         #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "#         x = torch.cat([x7,x],1) # 4,16,7501\n",
    "#         x = self.concat7_shape(x) \n",
    "#         x = F.pad(x, pad = (130, 0, 0, 0)) \n",
    "#         x = self.t_conv1(x) # 4,8,7501\n",
    "#         #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x6,x],1)\n",
    "#         x = self.concat6_shape(x)\n",
    "#         x = F.pad(x, pad = (66, 0, 0, 0))\n",
    "#         x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x5,x],1)\n",
    "#         x = self.concat5_shape(x)\n",
    "#         x = F.pad(x, pad = (34, 0, 0, 0))\n",
    "#         x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x4,x],1)\n",
    "#         x = self.concat4_shape(x)\n",
    "#         x = F.pad(x, pad = (18, 0, 0, 0))\n",
    "#         x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x3,x],1)\n",
    "#         x = self.concat3_shape(x)\n",
    "#         x = F.pad(x, pad = (10, 0, 0, 0))\n",
    "#         x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x2,x],1)\n",
    "#         x = self.concat2_shape(x)\n",
    "#         x = F.pad(x, pad = (6, 0, 0, 0))\n",
    "#         x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x1,x],1)\n",
    "#         x = self.concat1_shape(x)\n",
    "#         x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "#         x = self.t_conv7(x)\n",
    "    \n",
    "        \n",
    "#         #print(x.shape)\n",
    "#         #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "#         return encode, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeAutoEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchmetrics\n",
    "#from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "#criterion = MeanAbsolutePercentageError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e766e26e97564a0ca06800f194c121ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 938.00 MiB (GPU 0; 3.00 GiB total capacity; 1.15 GiB already allocated; 233.50 MiB free; 1.17 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f977e002f704>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch_li\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_li\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-87ab49f58868>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0287f7bf32e7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mel_spec)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m#print(x1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2281\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 938.00 MiB (GPU 0; 3.00 GiB total capacity; 1.15 GiB already allocated; 233.50 MiB free; 1.17 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_dir = '/home/work/Tcae_apply/model_dir9/'\n",
    "min_loss = 987654321\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "#tloss_list=[]\n",
    "#vloss_list=[]\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    train_loss = train(model = model, train_loader = train_batch_li) \n",
    "    val_loss = val(model = model, train_loader = val_batch_li) \n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    #tloss_list.append(train_loss)\n",
    "    #vloss_list.append(val_loss)\n",
    "    \n",
    "    print(f'EPOCH:{epoch}, Train Loss:{train_loss}, Val Loss:{val_loss}, 학습 시간: {end - start}')\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_dir + f'TimeAutoEncoder_val.pt')\n",
    "        print('모델 저장')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_embeding_li = get_mel_embeding(model = model, train_loader = test_batch_li)\n",
    "#mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(batch_data_dir + 'mel_embeding_val.npy', mel_embeding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
