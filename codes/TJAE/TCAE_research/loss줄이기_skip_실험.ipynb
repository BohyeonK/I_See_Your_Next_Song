{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os \n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/work/'\n",
    "np1 = glob.glob(base_dir+'mel_dataset1/*.npy')\n",
    "np2 = glob.glob(base_dir+'mel_dataset2/*.npy')\n",
    "np3 = glob.glob(base_dir+'mel_dataset3/*.npy')\n",
    "np4 = glob.glob(base_dir+'mel_dataset4/*.npy')\n",
    "np5 = glob.glob(base_dir+'mel_dataset5/*.npy')\n",
    "np6 = glob.glob(base_dir+'mel_dataset6/*.npy')\n",
    "np7 = glob.glob(base_dir+'mel_dataset7/*.npy')\n",
    "np8 = glob.glob(base_dir+'mel_dataset8/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np1+np2+np3+np4+np5+np6+np7+np8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('new_train.csv')\n",
    "valid_csv = pd.read_csv('new_valid.csv')\n",
    "all_csv =pd.read_csv('new_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3807ebec395447bfbb30bd597142a94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99727a1a762483793902a6ce88d4a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def npy_list(csv):\n",
    "    npy_list = []\n",
    "    for song_path in tqdm(csv['npy_path']):\n",
    "        song_npy = np.load(song_path).squeeze()\n",
    "        #npy_list.append(song_npy[-1876:])\n",
    "        npy_list.append(song_npy)\n",
    "        \n",
    "    return npy_list\n",
    "\n",
    "train_list = [np.load(song_path).squeeze() for song_path in tqdm(train_csv['npy_path'])]\n",
    "valid_list = [np.load(song_path).squeeze() for song_path in tqdm(valid_csv['npy_path'])]\n",
    "#train_list = npy_list(train_csv)\n",
    "#valid_list = npy_list(valid_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = train_list + valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch문 안에 들어가야되나?\n",
    "#train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denoise encoding\n",
    "def add_noise(data):\n",
    "    noise = torch.randn(data.size()) * 0.2 \n",
    "    # 무작위 작음은 torch.randn() 함수로 만들고 img.size()를 넣어 이미지와 같은 크기의 잡음을 만듭니다.\n",
    "    # 잡음의 강도는 임의로 0.2로 정했습니다.\n",
    "    noisy_data = data + noise\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = add_noise(batch) # denoise encoding\n",
    "        mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        encode, output = model(mel)\n",
    "\n",
    "        loss = criterion(output, mel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= (len(train_loader))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def val(model, train_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "\n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "\n",
    "            encode, output = model(mel)\n",
    "\n",
    "            loss = criterion(output, mel)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= (len(train_loader))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def get_mel_embeding(model, train_loader):\n",
    "    model.eval()\n",
    "    mel_embeding_li = []\n",
    "    pre_encode_li = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader: \n",
    "\n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "\n",
    "            encode, output, pre_encode = model(mel)\n",
    "\n",
    "            mel_embeding_li.append(encode.detach().cpu().numpy())\n",
    "            pre_encode_li.append(pre_encode.detach().cpu().numpy())\n",
    "    return mel_embeding_li, pre_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ 원래 ##############\n",
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "#             nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "#             nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "#             nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "#             nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "#             nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "#             nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "#             nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "#             nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "#             nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "#             nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 1024, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x1 = self.conv1(x)\n",
    "        #print(x1.shape)\n",
    "        x = F.pad(x1, pad = (4, 0, 0, 0))\n",
    "        x2 = self.conv2(x)\n",
    "        #print(x2.shape)\n",
    "        x = F.pad(x2, pad = (8, 0, 0, 0))\n",
    "        x3 = self.conv3(x)\n",
    "        #print(x3.shape)\n",
    "        x = F.pad(x3, pad = (16, 0, 0, 0))\n",
    "        x4 = self.conv4(x)\n",
    "        #print(x4.shape)\n",
    "        x = F.pad(x4, pad = (32, 0, 0, 0))\n",
    "        x5 = self.conv5(x)\n",
    "        #print(x5.shape)\n",
    "        x = F.pad(x5, pad = (64, 0, 0, 0))\n",
    "        x6 = self.conv6(x)\n",
    "        #print(x6.shape)\n",
    "        x = F.pad(x6, pad = (128, 0, 0, 0))\n",
    "        x7 = self.conv7(x)\n",
    "        pre_encode = x7\n",
    "        #print(x7.shape)\n",
    "        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        x = torch.cat([x7,x],1) # 4,16,7501\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0)) \n",
    "        x = self.t_conv1(x) # 4,8,7501\n",
    "        #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x6,x],1)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x5,x],1)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x4,x],1)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x3,x],1)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x2,x],1)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x1,x],1)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x, pre_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # no dilation\n",
    "# # encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# # decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "# class TimeAutoEncoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TimeAutoEncoder, self).__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv4 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv5 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv6 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv7 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.encoder_fc = nn.Sequential(\n",
    "#             nn.Linear(8 * 7501, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder_fc = nn.Sequential(\n",
    "#             nn.Linear(128, 8 * 7501),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv1 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "#             nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv2 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv3 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv4 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv5 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv6 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv7 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, mel_spec):\n",
    "#         x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv1(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv2(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv3(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv4(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv5(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv6(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.conv7(x)\n",
    "#         #print(x.shape)\n",
    "#         encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "#         #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "#         # print('decode')\n",
    "#         x = self.decoder_fc(encode)\n",
    "#         x = x.view(-1, 8, 7501)\n",
    "#         x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv1(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv2(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv3(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv4(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv5(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv6(x)\n",
    "#         #print(x.shape)\n",
    "#         x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "#         x = self.t_conv7(x)\n",
    "#         #print(x.shape)\n",
    "#         x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "#         return encode, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # skip connection\n",
    "# # encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# # decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "# class TimeAutoEncoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TimeAutoEncoder, self).__init__()\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv3 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv4 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv5 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv6 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.conv7 = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.encoder_fc = nn.Sequential(\n",
    "#             nn.Linear(8 * 7501, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Tanh(),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder_fc = nn.Sequential(\n",
    "#             nn.Linear(128, 8 * 7501),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv1 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "#             nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv2 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv3 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv4 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv5 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv6 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "#         )\n",
    "\n",
    "#         self.t_conv7 = nn.Sequential(\n",
    "#             # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "#         )\n",
    "\n",
    "#         self.concat7_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(8),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat6_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(16),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat5_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat4_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat3_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat2_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "#         self.concat1_shape = nn.Sequential(\n",
    "#             nn.Conv1d(in_channels = 1024, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "#             nn.BatchNorm1d(512),\n",
    "#             nn.ReLU(),\n",
    "            \n",
    "#         )\n",
    "        \n",
    "        \n",
    "#     def forward(self, mel_spec):\n",
    "#         x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "#         x1 = self.conv1(x)\n",
    "#         #print(x1.shape)\n",
    "#         x = F.pad(x1, pad = (4, 0, 0, 0))\n",
    "#         x2 = self.conv2(x)\n",
    "#         #print(x2.shape)\n",
    "#         x = F.pad(x2, pad = (8, 0, 0, 0))\n",
    "#         x3 = self.conv3(x)\n",
    "#         #print(x3.shape)\n",
    "#         x = F.pad(x3, pad = (16, 0, 0, 0))\n",
    "#         x4 = self.conv4(x)\n",
    "#         #print(x4.shape)\n",
    "#         x = F.pad(x4, pad = (32, 0, 0, 0))\n",
    "#         x5 = self.conv5(x)\n",
    "#         #print(x5.shape)\n",
    "#         x = F.pad(x5, pad = (64, 0, 0, 0))\n",
    "#         x6 = self.conv6(x)\n",
    "#         #print(x6.shape)\n",
    "#         x = F.pad(x6, pad = (128, 0, 0, 0))\n",
    "#         x7 = self.conv7(x)\n",
    "#         #print(x7.shape)\n",
    "#         encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "#         #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "#         # print('decode')\n",
    "#         x = self.decoder_fc(encode)\n",
    "#         x = x.view(-1, 8, 7501)\n",
    "#         #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "#         x = torch.cat([x7,x],1) # 4,16,7501\n",
    "#         x = self.concat7_shape(x) \n",
    "#         x = F.pad(x, pad = (130, 0, 0, 0)) \n",
    "#         x = self.t_conv1(x) # 4,8,7501\n",
    "#         #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x6,x],1)\n",
    "#         x = self.concat6_shape(x)\n",
    "#         x = F.pad(x, pad = (66, 0, 0, 0))\n",
    "#         x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x5,x],1)\n",
    "#         x = self.concat5_shape(x)\n",
    "#         x = F.pad(x, pad = (34, 0, 0, 0))\n",
    "#         x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x4,x],1)\n",
    "#         x = self.concat4_shape(x)\n",
    "#         x = F.pad(x, pad = (18, 0, 0, 0))\n",
    "#         x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x3,x],1)\n",
    "#         x = self.concat3_shape(x)\n",
    "#         x = F.pad(x, pad = (10, 0, 0, 0))\n",
    "#         x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x2,x],1)\n",
    "#         x = self.concat2_shape(x)\n",
    "#         x = F.pad(x, pad = (6, 0, 0, 0))\n",
    "#         x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x = torch.cat([x1,x],1)\n",
    "#         x = self.concat1_shape(x)\n",
    "#         x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "#         x = self.t_conv7(x)\n",
    "    \n",
    "        \n",
    "#         #print(x.shape)\n",
    "#         #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "#         return encode, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeAutoEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchmetrics\n",
    "#from torchmetrics import MeanAbsolutePercentageError\n",
    "\n",
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "#criterion = MeanAbsolutePercentageError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de238f7deb6941c19325d28f762b76f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1, Train Loss:187516.19592492055, Val Loss:14629.8775390625, 학습 시간: 40.36835765838623\n",
      "모델 저장\n",
      "EPOCH:2, Train Loss:13138.638638771186, Val Loss:8613.606591796875, 학습 시간: 42.40225696563721\n",
      "모델 저장\n",
      "EPOCH:3, Train Loss:6086.3719999668965, Val Loss:3656.101904296875, 학습 시간: 42.82729411125183\n",
      "모델 저장\n",
      "EPOCH:4, Train Loss:3132.2222590042375, Val Loss:2255.9148071289064, 학습 시간: 40.606762170791626\n",
      "모델 저장\n",
      "EPOCH:5, Train Loss:1919.5777422371557, Val Loss:1552.2092041015626, 학습 시간: 40.30139780044556\n",
      "모델 저장\n",
      "EPOCH:6, Train Loss:1388.4366165419756, Val Loss:1158.4067993164062, 학습 시간: 41.14859366416931\n",
      "모델 저장\n",
      "EPOCH:7, Train Loss:1102.7504127631753, Val Loss:1002.5201782226562, 학습 시간: 39.95686912536621\n",
      "모델 저장\n",
      "EPOCH:8, Train Loss:1018.543230477026, Val Loss:830.7598327636719, 학습 시간: 41.264671087265015\n",
      "모델 저장\n",
      "EPOCH:9, Train Loss:797.8274334406449, Val Loss:782.9164367675781, 학습 시간: 40.853734731674194\n",
      "EPOCH:10, Train Loss:723.1134493553033, Val Loss:650.6698181152344, 학습 시간: 41.26861524581909\n",
      "모델 저장\n",
      "EPOCH:11, Train Loss:693.6109836384402, Val Loss:726.4272521972656, 학습 시간: 40.51658582687378\n",
      "EPOCH:12, Train Loss:698.2486856751523, Val Loss:547.2157745361328, 학습 시간: 40.027957916259766\n",
      "모델 저장\n",
      "EPOCH:13, Train Loss:524.0049619513043, Val Loss:485.9714599609375, 학습 시간: 40.26890230178833\n",
      "모델 저장\n",
      "모델 저장\n",
      "EPOCH:15, Train Loss:452.95782315529, Val Loss:420.9980407714844, 학습 시간: 40.06906580924988\n",
      "모델 저장\n",
      "EPOCH:16, Train Loss:471.70378449003573, Val Loss:460.55830078125, 학습 시간: 40.07328820228577\n",
      "EPOCH:17, Train Loss:428.11454436738615, Val Loss:402.97351989746096, 학습 시간: 39.42378807067871\n",
      "모델 저장\n",
      "EPOCH:18, Train Loss:372.04065975900426, Val Loss:405.2081268310547, 학습 시간: 39.918572664260864\n",
      "EPOCH:19, Train Loss:412.0754342806541, Val Loss:353.9000305175781, 학습 시간: 41.95177960395813\n",
      "모델 저장\n",
      "EPOCH:20, Train Loss:344.0232492220604, Val Loss:318.19867248535155, 학습 시간: 42.05232381820679\n",
      "모델 저장\n",
      "EPOCH:21, Train Loss:321.2007376460706, Val Loss:324.4898223876953, 학습 시간: 40.684086561203\n",
      "EPOCH:22, Train Loss:425.2443705413301, Val Loss:510.45050048828125, 학습 시간: 40.43402624130249\n",
      "EPOCH:23, Train Loss:347.81153326519467, Val Loss:279.6818145751953, 학습 시간: 40.22855997085571\n",
      "모델 저장\n",
      "EPOCH:24, Train Loss:264.26143555721995, Val Loss:245.12096252441407, 학습 시간: 41.053138256073\n",
      "모델 저장\n",
      "EPOCH:25, Train Loss:243.2198152703754, Val Loss:237.98002014160156, 학습 시간: 40.999354124069214\n",
      "모델 저장\n",
      "EPOCH:26, Train Loss:243.05311118950277, Val Loss:232.35757904052736, 학습 시간: 41.32250785827637\n",
      "모델 저장\n",
      "EPOCH:27, Train Loss:241.19134857694982, Val Loss:215.10731658935546, 학습 시간: 40.131391525268555\n",
      "모델 저장\n",
      "EPOCH:28, Train Loss:358.61766776392017, Val Loss:288.2131286621094, 학습 시간: 40.12158441543579\n",
      "EPOCH:29, Train Loss:251.24815627275888, Val Loss:202.57268981933595, 학습 시간: 39.85195589065552\n",
      "모델 저장\n",
      "EPOCH:30, Train Loss:201.68774439924854, Val Loss:206.44678192138673, 학습 시간: 40.0313618183136\n",
      "EPOCH:31, Train Loss:199.99463433734442, Val Loss:181.2714828491211, 학습 시간: 40.45250082015991\n",
      "모델 저장\n",
      "EPOCH:32, Train Loss:220.4494048296395, Val Loss:208.8191390991211, 학습 시간: 40.68215799331665\n",
      "EPOCH:33, Train Loss:183.25151165461136, Val Loss:199.08413696289062, 학습 시간: 41.502358198165894\n",
      "EPOCH:34, Train Loss:191.12037516448459, Val Loss:162.33623352050782, 학습 시간: 40.62735629081726\n",
      "모델 저장\n",
      "EPOCH:35, Train Loss:176.4435362735037, Val Loss:162.01996917724608, 학습 시간: 40.107006549835205\n",
      "모델 저장\n",
      "EPOCH:36, Train Loss:160.71182651843054, Val Loss:161.87074661254883, 학습 시간: 40.31166672706604\n",
      "모델 저장\n",
      "EPOCH:37, Train Loss:178.64472289004567, Val Loss:140.7688316345215, 학습 시간: 41.05631470680237\n",
      "모델 저장\n",
      "EPOCH:38, Train Loss:145.6287178427486, Val Loss:142.765389251709, 학습 시간: 41.418328285217285\n",
      "EPOCH:39, Train Loss:160.574313923464, Val Loss:246.4084457397461, 학습 시간: 41.43582725524902\n",
      "EPOCH:40, Train Loss:194.33025760973914, Val Loss:134.63586807250977, 학습 시간: 41.10836100578308\n",
      "모델 저장\n",
      "EPOCH:41, Train Loss:149.536386004949, Val Loss:167.356689453125, 학습 시간: 42.053401470184326\n",
      "EPOCH:42, Train Loss:158.9504614361262, Val Loss:195.5660842895508, 학습 시간: 40.18845725059509\n",
      "EPOCH:43, Train Loss:140.84891367766818, Val Loss:112.27530517578126, 학습 시간: 39.862213373184204\n",
      "모델 저장\n",
      "EPOCH:44, Train Loss:120.30053335933361, Val Loss:114.8829444885254, 학습 시간: 40.76358771324158\n",
      "EPOCH:45, Train Loss:110.03685359631555, Val Loss:106.32664413452149, 학습 시간: 40.689773082733154\n",
      "모델 저장\n",
      "EPOCH:46, Train Loss:140.54804488359872, Val Loss:145.0565315246582, 학습 시간: 40.35781121253967\n",
      "EPOCH:47, Train Loss:117.42663470769332, Val Loss:103.69478302001953, 학습 시간: 40.511817932128906\n",
      "모델 저장\n",
      "EPOCH:48, Train Loss:109.04729629775225, Val Loss:106.8946319580078, 학습 시간: 40.801207304000854\n",
      "EPOCH:49, Train Loss:117.2899544926013, Val Loss:99.50531997680665, 학습 시간: 41.106480836868286\n",
      "모델 저장\n",
      "EPOCH:50, Train Loss:113.88978912870763, Val Loss:115.62169876098633, 학습 시간: 41.201730251312256\n",
      "EPOCH:51, Train Loss:106.99208663681806, Val Loss:108.47179641723633, 학습 시간: 39.81594252586365\n",
      "EPOCH:52, Train Loss:123.9561511540817, Val Loss:87.461962890625, 학습 시간: 40.55583596229553\n",
      "모델 저장\n",
      "EPOCH:53, Train Loss:86.79021718946554, Val Loss:95.04229583740235, 학습 시간: 40.73577523231506\n",
      "EPOCH:54, Train Loss:93.75097475213519, Val Loss:89.86928253173828, 학습 시간: 40.52657151222229\n",
      "EPOCH:55, Train Loss:158.11460029472738, Val Loss:133.43854217529298, 학습 시간: 40.09106969833374\n",
      "EPOCH:56, Train Loss:90.15789187156548, Val Loss:69.27200088500976, 학습 시간: 41.52644610404968\n",
      "모델 저장\n",
      "EPOCH:57, Train Loss:83.683079412428, Val Loss:89.05205535888672, 학습 시간: 39.24312996864319\n",
      "EPOCH:58, Train Loss:79.01813675185382, Val Loss:71.02560386657714, 학습 시간: 39.73425602912903\n",
      "EPOCH:59, Train Loss:78.70021154112735, Val Loss:67.58811798095704, 학습 시간: 39.54378008842468\n",
      "모델 저장\n",
      "EPOCH:60, Train Loss:71.13476846985898, Val Loss:69.01723098754883, 학습 시간: 39.12548089027405\n",
      "EPOCH:61, Train Loss:79.49632243786829, Val Loss:68.22732505798339, 학습 시간: 40.662781953811646\n",
      "EPOCH:62, Train Loss:70.67587183289609, Val Loss:58.3671329498291, 학습 시간: 40.341379165649414\n",
      "모델 저장\n",
      "EPOCH:63, Train Loss:65.04751548120531, Val Loss:103.84112777709962, 학습 시간: 39.77401900291443\n",
      "EPOCH:64, Train Loss:211.27896092301708, Val Loss:195.95087280273438, 학습 시간: 39.712833642959595\n",
      "EPOCH:65, Train Loss:107.45594102245266, Val Loss:74.67916679382324, 학습 시간: 39.94350481033325\n",
      "EPOCH:66, Train Loss:67.92636942459364, Val Loss:59.72581520080566, 학습 시간: 40.335838079452515\n",
      "EPOCH:67, Train Loss:57.02784586760957, Val Loss:56.71227035522461, 학습 시간: 41.242528200149536\n",
      "모델 저장\n",
      "EPOCH:68, Train Loss:72.19533467696886, Val Loss:62.63209609985351, 학습 시간: 39.653327226638794\n",
      "EPOCH:69, Train Loss:62.190450442039364, Val Loss:57.825934982299806, 학습 시간: 40.34912848472595\n",
      "EPOCH:70, Train Loss:66.14217253862802, Val Loss:59.799883651733396, 학습 시간: 39.468544244766235\n",
      "EPOCH:71, Train Loss:61.46931560968949, Val Loss:48.3077896118164, 학습 시간: 39.76941275596619\n",
      "모델 저장\n",
      "EPOCH:72, Train Loss:49.38422943373858, Val Loss:50.355855560302736, 학습 시간: 39.820120334625244\n",
      "EPOCH:73, Train Loss:57.36503672195693, Val Loss:52.29676628112793, 학습 시간: 39.662649154663086\n",
      "EPOCH:74, Train Loss:56.901272208003675, Val Loss:57.21396942138672, 학습 시간: 39.87448859214783\n",
      "EPOCH:75, Train Loss:58.75527714874785, Val Loss:55.52610816955566, 학습 시간: 40.19816994667053\n",
      "EPOCH:76, Train Loss:63.89167365381273, Val Loss:87.11523971557617, 학습 시간: 40.47442674636841\n",
      "EPOCH:77, Train Loss:56.93699077024298, Val Loss:49.71211204528809, 학습 시간: 40.32832098007202\n",
      "EPOCH:78, Train Loss:50.917371652894104, Val Loss:45.545266723632814, 학습 시간: 40.050864696502686\n",
      "모델 저장\n",
      "EPOCH:79, Train Loss:51.44106024402683, Val Loss:53.10618095397949, 학습 시간: 39.32358717918396\n",
      "EPOCH:80, Train Loss:63.70168608326023, Val Loss:44.902033996582034, 학습 시간: 39.825079917907715\n",
      "모델 저장\n",
      "EPOCH:81, Train Loss:41.89457705869513, Val Loss:47.22125053405762, 학습 시간: 40.004844188690186\n",
      "EPOCH:82, Train Loss:63.13550638748428, Val Loss:70.06193809509277, 학습 시간: 39.27237272262573\n",
      "EPOCH:84, Train Loss:52.86731946266303, Val Loss:52.3361198425293, 학습 시간: 40.273401975631714\n",
      "EPOCH:85, Train Loss:43.76363980568061, Val Loss:40.319087219238284, 학습 시간: 40.734293937683105\n",
      "모델 저장\n",
      "EPOCH:86, Train Loss:34.71405139211881, Val Loss:162.7877395629883, 학습 시간: 40.39174199104309\n",
      "EPOCH:87, Train Loss:82.45214998924126, Val Loss:40.68328971862793, 학습 시간: 41.18221616744995\n",
      "EPOCH:88, Train Loss:38.732873787314205, Val Loss:47.609326171875, 학습 시간: 40.03247404098511\n",
      "EPOCH:89, Train Loss:44.20293378021758, Val Loss:29.49313430786133, 학습 시간: 39.68504452705383\n",
      "모델 저장\n",
      "EPOCH:90, Train Loss:39.8462494672355, Val Loss:46.14232978820801, 학습 시간: 39.69749474525452\n",
      "EPOCH:91, Train Loss:50.43716614933337, Val Loss:31.73169708251953, 학습 시간: 39.81614565849304\n",
      "EPOCH:92, Train Loss:37.69835158525887, Val Loss:37.720384979248045, 학습 시간: 40.61819911003113\n",
      "EPOCH:93, Train Loss:34.574675867113015, Val Loss:36.181616401672365, 학습 시간: 40.256916761398315\n",
      "EPOCH:94, Train Loss:37.00523832288839, Val Loss:33.831922340393064, 학습 시간: 39.83057761192322\n",
      "EPOCH:95, Train Loss:39.44421047275349, Val Loss:37.01427879333496, 학습 시간: 40.011626958847046\n",
      "EPOCH:96, Train Loss:44.45529818130752, Val Loss:30.495128440856934, 학습 시간: 39.775153160095215\n",
      "EPOCH:97, Train Loss:32.38820463924085, Val Loss:25.1208984375, 학습 시간: 40.0854058265686\n",
      "모델 저장\n",
      "EPOCH:98, Train Loss:37.69243767301915, Val Loss:35.29222946166992, 학습 시간: 40.30943012237549\n",
      "EPOCH:99, Train Loss:53.23105740951279, Val Loss:63.72694969177246, 학습 시간: 40.40789341926575\n",
      "EPOCH:100, Train Loss:47.03551221297959, Val Loss:25.481019020080566, 학습 시간: 39.8167667388916\n",
      "EPOCH:101, Train Loss:28.950701067003152, Val Loss:52.26832885742188, 학습 시간: 39.700260639190674\n",
      "EPOCH:102, Train Loss:39.14313849756273, Val Loss:27.57907485961914, 학습 시간: 39.21052074432373\n",
      "EPOCH:103, Train Loss:27.724964141845703, Val Loss:27.99301872253418, 학습 시간: 41.121111154556274\n",
      "EPOCH:104, Train Loss:28.18793539273537, Val Loss:23.15728302001953, 학습 시간: 40.92224860191345\n",
      "모델 저장\n",
      "EPOCH:105, Train Loss:27.573421833878857, Val Loss:20.157876014709473, 학습 시간: 40.02388405799866\n",
      "EPOCH:106, Train Loss:23.706709344508283, Val Loss:23.82841091156006, 학습 시간: 39.52072191238403\n",
      "EPOCH:107, Train Loss:26.795381174249165, Val Loss:62.773749923706056, 학습 시간: 38.70047378540039\n",
      "EPOCH:108, Train Loss:50.937247971356925, Val Loss:24.878213310241698, 학습 시간: 40.347832441329956\n",
      "EPOCH:109, Train Loss:25.24805581367622, Val Loss:26.68989505767822, 학습 시간: 40.124871253967285\n",
      "EPOCH:110, Train Loss:32.99656557632705, Val Loss:31.080332946777343, 학습 시간: 39.91500759124756\n",
      "EPOCH:111, Train Loss:28.516501248893093, Val Loss:21.761275482177734, 학습 시간: 39.855855226516724\n",
      "EPOCH:112, Train Loss:26.283913644693666, Val Loss:22.578995513916016, 학습 시간: 40.490190267562866\n",
      "모델 저장\n",
      "EPOCH:114, Train Loss:40.37542503162966, Val Loss:53.65400085449219, 학습 시간: 40.64059400558472\n",
      "EPOCH:116, Train Loss:31.787343607110493, Val Loss:34.68230419158935, 학습 시간: 40.23839545249939\n",
      "EPOCH:117, Train Loss:31.874328128362105, Val Loss:29.39796314239502, 학습 시간: 39.41314768791199\n",
      "EPOCH:118, Train Loss:31.01716943514549, Val Loss:21.460700225830077, 학습 시간: 40.145082235336304\n",
      "EPOCH:119, Train Loss:22.129615347264178, Val Loss:18.256812286376952, 학습 시간: 40.934001445770264\n",
      "모델 저장\n",
      "EPOCH:120, Train Loss:25.27223908699165, Val Loss:28.773217391967773, 학습 시간: 40.783960580825806\n",
      "EPOCH:121, Train Loss:30.280535099870068, Val Loss:24.415233039855956, 학습 시간: 40.80380868911743\n",
      "EPOCH:122, Train Loss:25.619596853094585, Val Loss:29.386046409606934, 학습 시간: 40.01347351074219\n",
      "EPOCH:123, Train Loss:24.13511515471895, Val Loss:13.330265426635743, 학습 시간: 39.70230722427368\n",
      "모델 저장\n",
      "EPOCH:124, Train Loss:30.401746216466872, Val Loss:21.669690895080567, 학습 시간: 41.264981508255005\n",
      "EPOCH:125, Train Loss:16.97290249194129, Val Loss:20.917122650146485, 학습 시간: 40.211464643478394\n",
      "EPOCH:126, Train Loss:20.570420184377898, Val Loss:14.99377155303955, 학습 시간: 39.97001004219055\n",
      "EPOCH:127, Train Loss:19.78201816041591, Val Loss:82.23156204223633, 학습 시간: 39.5062530040741\n",
      "EPOCH:128, Train Loss:37.35419595039497, Val Loss:40.65758781433105, 학습 시간: 40.447051763534546\n",
      "EPOCH:129, Train Loss:24.143843230554612, Val Loss:14.571664428710937, 학습 시간: 40.24501013755798\n",
      "EPOCH:130, Train Loss:16.48327921204648, Val Loss:17.122874450683593, 학습 시간: 39.37291717529297\n",
      "EPOCH:131, Train Loss:33.74570985567772, Val Loss:31.681689453125, 학습 시간: 41.03203344345093\n",
      "EPOCH:132, Train Loss:34.890431339457884, Val Loss:22.604938983917236, 학습 시간: 41.06932187080383\n",
      "EPOCH:134, Train Loss:28.68171701592914, Val Loss:19.582340431213378, 학습 시간: 40.306883811950684\n",
      "EPOCH:135, Train Loss:19.530641879065563, Val Loss:15.527978610992431, 학습 시간: 39.81474590301514\n",
      "EPOCH:136, Train Loss:20.120413618572687, Val Loss:32.83909931182861, 학습 시간: 40.27240586280823\n",
      "EPOCH:137, Train Loss:21.265951205108124, Val Loss:13.325697898864746, 학습 시간: 40.257970094680786\n",
      "모델 저장\n",
      "EPOCH:138, Train Loss:17.346379732681534, Val Loss:12.654723644256592, 학습 시간: 39.85075044631958\n",
      "모델 저장\n",
      "EPOCH:139, Train Loss:17.40587483422231, Val Loss:33.33897323608399, 학습 시간: 39.766350507736206\n",
      "EPOCH:140, Train Loss:13.252440396001784, Val Loss:12.218004512786866, 학습 시간: 40.54365634918213\n",
      "모델 저장\n",
      "EPOCH:141, Train Loss:18.98611640121977, Val Loss:14.330014705657959, 학습 시간: 40.21529674530029\n",
      "EPOCH:142, Train Loss:22.23829073825125, Val Loss:19.400368022918702, 학습 시간: 40.25486898422241\n",
      "EPOCH:143, Train Loss:23.608814029370325, Val Loss:28.60152587890625, 학습 시간: 40.216612577438354\n",
      "EPOCH:144, Train Loss:16.639554120726505, Val Loss:9.779706382751465, 학습 시간: 40.80329990386963\n",
      "모델 저장\n",
      "EPOCH:145, Train Loss:9.784190622426696, Val Loss:15.777636623382568, 학습 시간: 40.48204565048218\n",
      "EPOCH:146, Train Loss:19.36597676196341, Val Loss:23.82992515563965, 학습 시간: 40.03459286689758\n",
      "EPOCH:147, Train Loss:20.633842241966118, Val Loss:17.99030418395996, 학습 시간: 40.597864866256714\n",
      "EPOCH:150, Train Loss:31.07616338891498, Val Loss:14.262141036987305, 학습 시간: 39.25238108634949\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_dir = '/home/work/Tcae_apply/model_dir/'\n",
    "min_loss = 987654321\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "#tloss_list=[]\n",
    "#vloss_list=[]\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start = time.time()\n",
    "    \n",
    "    \n",
    "    train_loss = train(model = model, train_loader = train_batch_li) \n",
    "    val_loss = val(model = model, train_loader = val_batch_li) \n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    #tloss_list.append(train_loss)\n",
    "    #vloss_list.append(val_loss)\n",
    "    \n",
    "    print(f'EPOCH:{epoch}, Train Loss:{train_loss}, Val Loss:{val_loss}, 학습 시간: {end - start}')\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_dir + f'TimeAutoEncoder_val_성현_v1.pt')\n",
    "        print('모델 저장')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = '/home/work/Tcae_apply/model_dir/'\n",
    "\n",
    "model = TimeAutoEncoder().to(DEVICE)\n",
    "model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_val_성현_v1.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_li = DataLoader(all_list, batch_size=64, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_embeding_li, pre_encode = get_mel_embeding(model = model, train_loader = test_batch_li)\n",
    "#mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       ...,\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.],\n",
       "       [-1.,  1., -1., ..., -1.,  1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_embeding_li[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1169e-03,\n",
       "          5.3192e-02, 6.4812e-02],\n",
       "         [4.7241e-02, 2.9495e-02, 1.2790e-04,  ..., 1.0428e-01,\n",
       "          1.0725e-01, 5.8025e-02],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          2.2643e-02, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.2812e-02,\n",
       "          0.0000e+00, 2.6420e-02],\n",
       "         [2.8736e-02, 4.4477e-02, 0.0000e+00,  ..., 1.0065e-02,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0163e-01,\n",
       "          2.4111e-01, 1.3009e-01],\n",
       "         [5.1669e-02, 5.1753e-02, 5.1823e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 7.6185e-03],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0627e-01,\n",
       "          2.7699e-01, 2.7346e-01],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [3.4689e-02, 3.4885e-02, 3.5305e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.6696e-01,\n",
       "          2.2387e-01, 2.6138e-01],\n",
       "         [7.1960e-02, 6.7693e-02, 5.9674e-02,  ..., 4.3398e-01,\n",
       "          7.9736e-02, 5.1587e-01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5608e-01,\n",
       "          3.5185e-01, 2.3829e-02],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [6.7791e-02, 7.0227e-02, 5.1270e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1618e-01,\n",
       "          1.4563e-01, 8.8189e-02],\n",
       "         [5.0022e-02, 5.4885e-02, 1.0598e-01,  ..., 6.8540e-02,\n",
       "          1.1970e-01, 1.2079e-02],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9005e-02,\n",
       "          3.1813e-02, 2.1341e-02],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 4.1161e-02,  ..., 3.7171e-02,\n",
       "          0.0000e+00, 4.5360e-02],\n",
       "         [4.8252e-02, 5.7024e-02, 6.5963e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.6253e-01,\n",
       "          3.0274e-01, 4.4423e-01],\n",
       "         [5.9698e-02, 5.8993e-02, 5.9018e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.5092e-01,\n",
       "          1.2185e-01, 3.5891e-01],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [5.4008e-02, 5.1651e-02, 5.1955e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          1.7777e-01, 1.4912e-02],\n",
       "         [8.2914e-02, 7.1703e-02, 8.1216e-02,  ..., 1.8751e-01,\n",
       "          8.8178e-03, 8.9931e-02],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.2389e-02],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.8852e-02,\n",
       "          0.0000e+00, 1.4421e-02],\n",
       "         [6.2750e-02, 6.4717e-02, 5.8371e-02,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 7.8827e-03]]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_embeding_li = get_mel_embeding(model = model, train_loader = test_batch_li)\n",
    "#mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(batch_data_dir + 'mel_embeding_val.npy', mel_embeding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
