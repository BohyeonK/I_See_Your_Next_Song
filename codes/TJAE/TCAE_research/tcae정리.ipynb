{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os \n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_min2_mel(song_paths='/home/work/Tcae_apply/tcae_inference_folder/wav_folder/존박_빗속에서.wav',sample_rate=16000): # song_paths = wav_path 입력\n",
    "    \n",
    "    wav, wav_sample_rate = torchaudio.load(song_paths)\n",
    "\n",
    "    if wav_sample_rate != sample_rate:\n",
    "        transform = torchaudio.transforms.Resample(wav_sample_rate, sample_rate)\n",
    "        wav = transform(wav)\n",
    "\n",
    "\n",
    "    wav = torch.unsqueeze(torch.mean(wav, axis=0), dim=0) # mono\n",
    "    wav_to_mel = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=512, hop_length=256, n_mels=48) # to mel\n",
    "\n",
    "    mel = wav_to_mel(wav)\n",
    "    mel = mel.cpu().detach().numpy() # 멜 임베딩을 numpy로\n",
    "\n",
    "    return mel # return : mel_embedding\n",
    "    \n",
    "        #song_name = os.path.splitext(song_paths[j])[0].split('/')[-1]\n",
    "        #np.save(f\"{save_dir}/{song_name}.npy\", mel) # 멜 스펙토그램_embedding이 저장되는 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/home/work/Tcae_apply/model_dir3/Tcae_apply/tcae_inference_folder/wav_folder/정하_보컬.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.load('/home/work/Tcae_apply/tcae_inference_folder/mel_folder/성현_보컬.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 8099)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#charlie\n",
    "############# 원래 ##############\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "            \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            #nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            #nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 4, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            #nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 256),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(256, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            #nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            #nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            #nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            #nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 1024, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 64)\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.conv1to3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )# out : 128 * 7501\n",
    "        \n",
    "        self.conv2to4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )# out : 64 * 7501\n",
    "        \n",
    "        self.conv3to5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )# out : 32 * 7501\n",
    "        \n",
    "        self.conv4to6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )# out : 16 * 7501\n",
    "        \n",
    "        self.conv5to7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 4, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            #nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )# out : 8 * 7501\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x1 = self.conv1(x) # 48 * 7501 => 512 * 7501 \n",
    "        print(x1.shape)\n",
    "        \n",
    "        x1to2 = F.pad(x1, pad = (4, 0, 0, 0)) #512 * 7501 \n",
    "        x1to3 = F.pad(x1, pad = (8, 0, 0, 0)) #512 * 7501 \n",
    "        #print('x1to2',x1to2.shape)\n",
    "        #print('x1to3',x1to3.shape)\n",
    "        \n",
    "        \n",
    "        x2 = self.conv2(x1to2) # 512 * 7501 => 256 * 7501\n",
    "        print(x2.shape)\n",
    "        \n",
    "        x2to3 = F.pad(x2, pad = (8, 0, 0, 0)) # 256 * 7501\n",
    "        #x2to4 = F.pad(x2, pad = (16, 0, 0, 0)) # 256 * 7501\n",
    "        #print('x2to3 :',x2to3.shape)\n",
    "        #print('x2to4 :',x2to3.shape)\n",
    "        \n",
    "        x3 = self.conv3(x2to3) # 256 * 7501 => 64 * 7501\n",
    "        x3_connec = self.conv1to3(x1to3) # In : 512 * 7501 , out: 64 * 7501     128\n",
    "        x3= torch.cat([x3,x3_connec],1) # 128 * 7501\n",
    "        print(x3.shape)\n",
    "        \n",
    "        \n",
    "        x3to4 = F.pad(x3, pad = (16, 0, 0, 0)) # 128 * 7501\n",
    "        x3to5 = F.pad(x3, pad = (32, 0, 0, 0)) # 128 * 7501\n",
    "        #print('x3to4 :',x3to4.shape)\n",
    "        #print('x3to5 :',x3to5.shape)\n",
    "        \n",
    "        x4 = self.conv4(x3to4) # 128 * 7501 => 64 * 7501\n",
    "        #x4_connec = self.conv2to4(x2to4) # In : 256 * 7501 , out : 32 * 7501 \n",
    "        #x4 = torch.cat([x4,x4_connec],1) # 64 * 7501\n",
    "        print(x4.shape)\n",
    "        \n",
    "        x4to5 = F.pad(x4, pad = (32, 0, 0, 0)) # 64 * 7501\n",
    "        #x4to6 = F.pad(x4, pad = (64, 0, 0, 0)) # 64 * 7501\n",
    "        #print('x4to5 :',x4to5.shape)\n",
    "        #print('x4to6 :',x4to6.shape)\n",
    "        \n",
    "        \n",
    "        x5 = self.conv5(x4to5) # 64 * 7501 = > 16 * 7501 \n",
    "        x5_connec = self.conv3to5(x3to5) # 128 * 7501 => 16 * 7501\n",
    "        x5 = torch.cat([x5,x5_connec],1) # 32 * 7501\n",
    "        print(x5.shape)\n",
    "        \n",
    "        x5to6 = F.pad(x5, pad = (64, 0, 0, 0)) # 32 * 7501\n",
    "        x5to7 = F.pad(x5, pad = (128, 0, 0, 0)) # 32 * 7501\n",
    "        #print('x5to6 :',x5to6.shape)\n",
    "        #print('x5to7 :',x5to7.shape)\n",
    "        \n",
    "        \n",
    "        x6 = self.conv6(x5to6) # 32 * 7501 => 16 * 7501\n",
    "        #x6_connec = self.conv4to6(x4to6) # 64 * 7501 => 8 * 7501\n",
    "        #x6 = torch.cat([x6,x6_connec],1) # 16 * 7501\n",
    "        print(x6.shape)\n",
    "        x6to7 = F.pad(x6, pad = (128, 0, 0, 0)) # 32 * 7501\n",
    "        #print('x6to7 :',x6to7.shape)\n",
    "        \n",
    "        \n",
    "        x7 = self.conv7(x6to7) # 16 * 7501 => 4 *7501 \n",
    "        pre_encode = torch.flatten(x7)\n",
    "        x7_connec = self.conv5to7(x5to7) # 32 * 7501 => 4 * 7501\n",
    "        x7 = torch.cat([x7,x7_connec],1) # 8 * 7501\n",
    "        print(x7.shape)\n",
    "        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        \n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        x = torch.cat([x7,x],1) # 4,16,7501\n",
    "        #x = self.concat7_shape(x) \n",
    "        x = F.pad(x, pad = (2, 0, 0, 0)) \n",
    "        x = self.t_conv1(x) # 4,8,7501\n",
    "        #print(x.shape,'new_cat7')\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x6,x],1)\n",
    "        #x = self.concat6_shape(x)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x5,x],1)\n",
    "        #x = self.concat5_shape(x)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x4,x],1)\n",
    "        #x = self.concat4_shape(x)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        \n",
    "        \n",
    "        x = torch.cat([x3,x],1)\n",
    "        #x = self.concat3_shape(x)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x2,x],1)\n",
    "        #x = self.concat2_shape(x)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = torch.cat([x1,x],1)\n",
    "        #x = self.concat1_shape(x)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        #x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_embeding(model, train_loader):\n",
    "    model.eval()\n",
    "    mel_embeding_li = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader: \n",
    "            \n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "            mel_embeding_li.append(encode.detach().cpu().numpy())\n",
    "\n",
    "    return mel_embeding_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_to_embedding():\n",
    "    mel = make_min2_mel(song_paths = '/home/work/Tcae_apply/tcae_inference_folder/wav_folder/존박_빗속에서.wav')\n",
    "    mel = [mel.squeeze()[:,:7501]]\n",
    "    inference_batch_li = DataLoader(mel, batch_size=1, shuffle=False,drop_last=False)\n",
    "\n",
    "    inference_model = TimeAutoEncoder().to(DEVICE)\n",
    "    inference_model.load_state_dict(torch.load('/home/work/Tcae_apply/model_dir3/TimeAutoEncoder_skipconnection_charlie_val.pt', map_location = DEVICE))\n",
    "\n",
    "    inference_embedding = get_mel_embeding(inference_model,inference_batch_li)\n",
    "    return inference_embedding\n",
    "    #pd.DataFrame(inference_embedding[0]).to_csv('TJAE/tjae_vocal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 7501])\n",
      "torch.Size([1, 256, 7501])\n",
      "torch.Size([1, 128, 7501])\n",
      "torch.Size([1, 64, 7501])\n",
      "torch.Size([1, 32, 7501])\n",
      "torch.Size([1, 16, 7501])\n",
      "torch.Size([1, 8, 7501])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-9.30863142e-01, -9.04240012e-01, -7.08037674e-01,\n",
       "         -9.41487491e-01, -9.50743794e-01, -9.85211015e-01,\n",
       "         -8.91448498e-01, -9.31205511e-01, -9.38048005e-01,\n",
       "         -8.72863829e-01, -8.37759018e-01, -8.56580257e-01,\n",
       "         -9.28934693e-01, -1.00395739e+00, -1.08263075e+00,\n",
       "         -8.01653862e-01, -9.14770961e-01, -8.90620351e-01,\n",
       "         -8.71596038e-01, -1.09121323e+00, -9.62611377e-01,\n",
       "         -8.80256712e-01, -1.04625058e+00, -9.40831482e-01,\n",
       "         -1.06616533e+00, -9.47073817e-01, -7.38908589e-01,\n",
       "         -2.02625847e+00, -1.02972150e+00, -1.03506660e+00,\n",
       "         -8.12007725e-01, -1.06731236e+00, -7.95435369e-01,\n",
       "         -1.08916581e+00, -9.67356980e-01, -9.11371887e-01,\n",
       "         -1.05690873e+00, -8.90077174e-01, -1.06327176e+00,\n",
       "         -8.43641818e-01, -1.03541291e+00, -8.35502088e-01,\n",
       "         -8.28084290e-01, -8.74129534e-01, -1.05727637e+00,\n",
       "         -1.09753442e+00, -1.00423384e+00, -1.08074403e+00,\n",
       "         -9.72967327e-01, -8.58922660e-01, -8.84200394e-01,\n",
       "         -9.68249261e-01, -9.09044564e-01, -9.41653967e-01,\n",
       "         -9.65784907e-01, -1.22769248e+00, -1.02974081e+00,\n",
       "         -9.88041520e-01, -7.54911184e-01, -9.43741679e-01,\n",
       "         -9.80536401e-01, -1.05184448e+00, -8.03838074e-01,\n",
       "         -1.07217014e+00, -8.22272241e-01, -1.09691668e+00,\n",
       "         -7.60870099e-01, -2.56111097e+00, -7.69471467e-01,\n",
       "         -1.04737461e+00, -7.74763942e-01, -9.91524994e-01,\n",
       "         -9.23659027e-01, -1.04520583e+00, -1.03130400e+00,\n",
       "         -8.73736620e-01, -9.78929818e-01, -1.07781541e+00,\n",
       "         -1.03990972e+00, -7.46975362e-01, -9.73358452e-01,\n",
       "         -6.65848970e-01, -1.09530318e+00, -1.05066371e+00,\n",
       "         -8.34452331e-01, -9.66165006e-01, -9.56678092e-01,\n",
       "         -9.73143995e-01, -8.88397932e-01, -1.04863107e+00,\n",
       "         -9.79502916e-01, -8.15758586e-01, -9.72288847e-01,\n",
       "         -1.07970119e+00, -1.05474746e+00, -1.07418573e+00,\n",
       "         -7.48296440e-01, -1.06232202e+00, -1.46105254e+00,\n",
       "         -9.18729827e-02, -1.06096041e+00, -1.05633807e+00,\n",
       "         -1.04253745e+00, -1.06558764e+00, -9.63453472e-01,\n",
       "         -1.06238341e+00, -9.42139804e-01, -1.09398901e+00,\n",
       "         -9.95178819e-01, -1.06011558e+00, -9.35478508e-01,\n",
       "         -1.07952881e+00, -1.09432459e+00, -1.05398285e+00,\n",
       "         -8.19570780e-01, -1.09481573e+00, -1.02061558e+00,\n",
       "         -9.50764120e-01, -1.07937765e+00, -8.45074117e-01,\n",
       "         -1.03366017e+00, -9.70552742e-01, -8.92999470e-01,\n",
       "         -1.09827411e+00, -9.32470679e-01, -1.08092058e+00,\n",
       "         -8.61616671e-01, -1.03582835e+00, -8.83152902e-01,\n",
       "         -9.37506437e-01, -9.17586863e-01, -1.05686641e+00,\n",
       "         -1.08287394e+00, -8.51166427e-01, -9.87274349e-01,\n",
       "         -1.08199012e+00, -1.04995286e+00, -1.05529094e+00,\n",
       "         -1.01565635e+00, -8.48589659e-01, -9.10396278e-01,\n",
       "         -9.68344927e-01, -1.08741724e+00, -9.74907279e-01,\n",
       "         -9.05847609e-01, -9.05145884e-01, -9.10901845e-01,\n",
       "         -8.94739211e-01, -1.06727719e+00, -1.05346477e+00,\n",
       "         -9.40996289e-01, -9.16419804e-01, -8.32473338e-01,\n",
       "         -1.00883734e+00, -9.67743039e-01, -9.59058464e-01,\n",
       "         -7.86225021e-01, -8.42272997e-01, -1.04251337e+00,\n",
       "         -1.08920431e+00, -9.57830310e-01, -9.80626881e-01,\n",
       "         -9.82619286e-01, -8.24962497e-01, -9.04150426e-01,\n",
       "         -1.06476831e+00, -8.61908197e-01, -9.83095288e-01,\n",
       "         -9.10326898e-01, -9.29450154e-01, -1.00069857e+00,\n",
       "         -9.01827097e-01, -7.58455932e-01,  1.16474266e+02,\n",
       "         -1.06850827e+00, -1.02861869e+00, -9.45349693e-01,\n",
       "         -1.07091725e+00, -9.14062321e-01, -9.11384344e-01,\n",
       "         -8.58414650e-01, -8.63669038e-01, -8.79534900e-01,\n",
       "         -9.58986163e-01, -8.93634081e-01, -9.58236992e-01,\n",
       "         -1.03270471e+00, -9.90643680e-01, -9.31268513e-01,\n",
       "         -1.04514170e+00, -1.00946236e+00, -7.76305735e-01,\n",
       "         -1.05468345e+00, -9.43926930e-01, -6.96940720e-01,\n",
       "         -8.14536631e-01, -8.36081922e-01, -1.02962720e+00,\n",
       "         -8.29834282e-01, -8.13812673e-01, -1.05303347e+00,\n",
       "         -9.96638238e-01, -6.04996979e-01, -9.71876442e-01,\n",
       "         -1.10714662e+00, -8.13034117e-01, -8.72635603e-01,\n",
       "         -1.05019724e+00, -9.31178570e-01, -9.96493280e-01,\n",
       "         -1.04133081e+00, -7.05435991e-01, -1.01577997e+00,\n",
       "         -1.08804452e+00, -6.66282356e-01, -1.00135505e+00,\n",
       "         -8.39299679e-01, -1.05716670e+00, -9.66369808e-01,\n",
       "         -1.06660569e+00, -9.48255718e-01, -1.05813205e+00,\n",
       "         -8.41157198e-01, -1.01256776e+00, -9.63097215e-01,\n",
       "         -9.81536329e-01, -9.72460628e-01, -9.88354146e-01,\n",
       "         -7.94009626e-01, -6.66417062e-01, -1.09070003e+00,\n",
       "         -9.14130449e-01, -1.07979310e+00, -1.08700144e+00,\n",
       "         -8.96911979e-01, -9.56492126e-01, -7.62208939e-01,\n",
       "         -1.00516653e+00, -9.82142627e-01, -9.74131227e-01,\n",
       "         -9.08152223e-01, -9.00477052e-01, -6.78613424e-01,\n",
       "         -8.42255533e-01, -1.06868291e+00, -8.93762052e-01,\n",
       "         -1.03165925e+00, -1.08912206e+00, -9.50468123e-01,\n",
       "         -6.56459272e-01, -9.03981209e-01, -1.05592752e+00,\n",
       "         -9.68363941e-01, -1.10374153e+00, -1.07558906e+00,\n",
       "         -6.40697539e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_to_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099bc44972e0402288fe0a944e59ef65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_dir = '/home/work/'\n",
    "inference_wav_path = base_dir + '/Tcae_apply/tcae_inference_folder/wav_folder/' # inference_wav가 '저장된 경로' \n",
    "#inference_mel_path = base_dir + '/Tcae_apply/tcae_inference_folder/mel_folder/' # inference_mel이 저장될 경로\n",
    "\n",
    "inference = [inference_wav_path+x for x in os.listdir(inference_wav_path)] # inference_wav list\n",
    "\n",
    "mel = make_min2_mel(song_paths = inference)\n",
    "mel = [mel.squeeze()[:,:7501]]\n",
    "inference_batch_li = DataLoader(mel, batch_size=1, shuffle=False,drop_last=False)\n",
    "# mel_embedding이 저장되는 경로\n",
    "# return inference의 멜 스펙토그램 npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_model = TimeAutoEncoder().to(DEVICE)\n",
    "model_dir = '/home/work/Tcae_apply/model_dir3/'\n",
    "inference_model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_skipconnection_charlie_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_embedding = get_mel_embeding(inference_model,inference_batch_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/home/work/Tcae_apply/model_dir3/TimeAutoEncoder_skipconnection_charlie_val.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.367964</td>\n",
       "      <td>-11.209202</td>\n",
       "      <td>-5.204</td>\n",
       "      <td>-11.691737</td>\n",
       "      <td>-12.434955</td>\n",
       "      <td>-11.375682</td>\n",
       "      <td>-3.83262</td>\n",
       "      <td>-11.711182</td>\n",
       "      <td>-11.474288</td>\n",
       "      <td>-10.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.475056</td>\n",
       "      <td>-13.220174</td>\n",
       "      <td>-12.013934</td>\n",
       "      <td>328.706451</td>\n",
       "      <td>-11.837992</td>\n",
       "      <td>-12.600722</td>\n",
       "      <td>-12.358846</td>\n",
       "      <td>-13.43066</td>\n",
       "      <td>-12.939454</td>\n",
       "      <td>-18.133314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1      2          3          4          5        6    \\\n",
       "0 -11.367964 -11.209202 -5.204 -11.691737 -12.434955 -11.375682 -3.83262   \n",
       "\n",
       "         7          8          9    ...        246        247        248  \\\n",
       "0 -11.711182 -11.474288 -10.857143  ... -12.475056 -13.220174 -12.013934   \n",
       "\n",
       "          249        250        251        252       253        254        255  \n",
       "0  328.706451 -11.837992 -12.600722 -12.358846 -13.43066 -12.939454 -18.133314  \n",
       "\n",
       "[1 rows x 256 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(inference_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_embedding():\n",
    "    inference_model = TimeAutoEncoder().to(DEVICE)\n",
    "    model_dir = '/home/work/Tcae_apply/model_dir3/'\n",
    "    inference_model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_skipconnection_charlie_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "\n",
    "#model_dir = '/home/work/Tcae_apply/model_dir3/'\n",
    "#model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_skipconnection_charlie_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/home/work/Tcae_apply/tcae_inference_folder/wav_folder/정하_보컬.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e8b45fef48b4ce38b0b4b748f63084d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "song_path = ['/home/work/Tcae_apply/tcae_inference_folder/wav_folder/정하_보컬.wav']\n",
    "mel = make_min2_mel(song_paths = song_path)# 멜 스펙토그램 npy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 7501)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel.squeeze()[:,:7501].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 8099)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [[[1,2,3]],[[2,4,5]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(48,7501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 4, 5]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb20ce0e04a5411a907112215140eaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inference_npy_path = '/home/work/Tcae_apply/tcae_inference_folder/mel_folder/'\n",
    "inference_npy_path = glob.glob(inference_npy_path + '*.npy')\n",
    "inference_list = [np.load(song_path).squeeze()[:,:7501] for song_path in tqdm(inference_npy_path)]\n",
    "inference_batch_li = DataLoader(inference_list, batch_size=1, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_embedding_li = get_mel_embeding(model = inference_model, train_loader = inference_batch_li)\n",
    "inference_embedding = np.concatenate(inference_embedding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('/home/work/Tcae_apply/tcae_inference_folder/mel_folder/정하_보컬.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 13233)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.squeeze()[:,:7501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 7501)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_batch_li = DataLoader([c], batch_size=1, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_embedding_li = get_mel_embeding(model = inference_model, train_loader = inference_batch_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(48,7501)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(48,7501),(48,7501),(48,7501)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 256)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 8099)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
