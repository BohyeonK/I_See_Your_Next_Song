{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import os \n",
    "from torch.nn import functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/work/'\n",
    "np1 = glob.glob(base_dir+'mel_dataset1/*.npy')\n",
    "np2 = glob.glob(base_dir+'mel_dataset2/*.npy')\n",
    "np3 = glob.glob(base_dir+'mel_dataset3/*.npy')\n",
    "np4 = glob.glob(base_dir+'mel_dataset4/*.npy')\n",
    "np5 = glob.glob(base_dir+'mel_dataset5/*.npy')\n",
    "np6 = glob.glob(base_dir+'mel_dataset6/*.npy')\n",
    "np7 = glob.glob(base_dir+'mel_dataset7/*.npy')\n",
    "np8 = glob.glob(base_dir+'mel_dataset8/*.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np1+np2+np3+np4+np5+np6+np7+np8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('new_train.csv')\n",
    "valid_csv = pd.read_csv('new_valid.csv')\n",
    "all_csv =pd.read_csv('new_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8750e8d4544f4fecb74e98f3cc30949b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3825 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3473c79b644a4a7f9a2ebdf7bd18dfc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def npy_list(csv):\n",
    "    npy_list = []\n",
    "    for song_path in tqdm(csv['npy_path']):\n",
    "        song_npy = np.load(song_path).squeeze()\n",
    "        npy_list.append(song_npy)\n",
    "    return npy_list\n",
    "\n",
    "\n",
    "train_list = npy_list(train_csv)\n",
    "valid_list = npy_list(valid_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = train_list + valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch문 안에 들어가야되나?\n",
    "#train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "#val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in train_loader: # 배치파일 다 만들면 train_loader [] 삭제하기\n",
    "        \n",
    "        #mel = np.load(batch_name)\n",
    "        mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        encode, output = model(mel)\n",
    "        \n",
    "        loss = criterion(output, mel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= (len(train_loader))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "def val(model, train_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:# 배치파일 다 만들면 train_loader [] 삭제하기\n",
    "            \n",
    "            #mel = np.load(batch_name)\n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "\n",
    "            encode, output = model(mel)\n",
    "\n",
    "            loss = criterion(output, mel)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= (len(train_loader))\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def get_mel_embeding(model, train_loader):\n",
    "    model.eval()\n",
    "    mel_embeding_li = []\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader: # 배치파일 다 만들면 train_loader [] 삭제하기\n",
    "            \n",
    "            #mel = np.load(batch_name)\n",
    "            mel = torch.FloatTensor(batch).to(DEVICE)\n",
    "            \n",
    "            encode, output = model(mel)\n",
    "            mel_embeding_li.append(encode.detach().cpu().numpy())\n",
    "\n",
    "    return mel_embeding_li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder <- 과거의 데이터를 바탕으로 미래를 예측 (t-1의 인과성 학습)\n",
    "# decoder <- 미래의 데이터를 바탕으로 과거를 예측 (t+1의 인과성 학습)\n",
    "class TimeAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TimeAutoEncoder, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_fc = nn.Sequential(\n",
    "            nn.Linear(8 * 7501, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(128, 8 * 7501),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv1 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n",
    "            nn.Conv1d(in_channels = 8, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv2 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n",
    "            nn.Conv1d(in_channels = 16, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv3 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n",
    "            nn.Conv1d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv4 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n",
    "            nn.Conv1d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv5 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n",
    "            nn.Conv1d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv6 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n",
    "            nn.Conv1d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.t_conv7 = nn.Sequential(\n",
    "            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n",
    "            nn.Conv1d(in_channels = 512, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, mel_spec):\n",
    "        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n",
    "        x = self.conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.conv7(x)\n",
    "        #print(x.shape)\n",
    "        encode = self.encoder_fc(x.view(-1, 8 * 7501))\n",
    "\n",
    "        #encode = self.encoder_fc(x.view(-1, 8 * 1876))\n",
    "\n",
    "        # print('decode')\n",
    "        x = self.decoder_fc(encode)\n",
    "        x = x.view(-1, 8, 7501)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        x = F.pad(x, pad = (128, 0, 0, 0))\n",
    "        x = self.t_conv1(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (64, 0, 0, 0))\n",
    "        x = self.t_conv2(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (32, 0, 0, 0))\n",
    "        x = self.t_conv3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (16, 0, 0, 0))\n",
    "        x = self.t_conv4(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (8, 0, 0, 0))\n",
    "        x = self.t_conv5(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (4, 0, 0, 0))\n",
    "        x = self.t_conv6(x)\n",
    "        #print(x.shape)\n",
    "        x = F.pad(x, pad = (2, 0, 0, 0))\n",
    "        x = self.t_conv7(x)\n",
    "        #print(x.shape)\n",
    "        x = torch.swapaxes(torch.fliplr(torch.swapaxes(x, 1, 2)), 1, 2)\n",
    "        \n",
    "        return encode, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimeAutoEncoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6778b77cce534584b54df635ac2bf822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:1, Train Loss:17833.780691964286, Val Loss:18560.346819196428, 학습 시간: 26.33114504814148\n",
      "모델 저장\n",
      "EPOCH:2, Train Loss:17316.818523503152, Val Loss:17546.024460565477, 학습 시간: 25.320499897003174\n",
      "모델 저장\n",
      "EPOCH:3, Train Loss:16773.10792246586, Val Loss:17579.230143229168, 학습 시간: 25.92996597290039\n",
      "EPOCH:8, Train Loss:14877.210822610294, Val Loss:17489.569847470237, 학습 시간: 26.00956082344055\n",
      "EPOCH:9, Train Loss:14505.108587184874, Val Loss:17390.005905877977, 학습 시간: 25.926118850708008\n",
      "EPOCH:10, Train Loss:14236.222007943803, Val Loss:17526.696475074405, 학습 시간: 25.95997977256775\n",
      "EPOCH:11, Train Loss:13988.963559447217, Val Loss:17471.2265625, 학습 시간: 25.54423451423645\n",
      "EPOCH:12, Train Loss:13595.595013786764, Val Loss:17938.92354910714, 학습 시간: 25.473011016845703\n",
      "EPOCH:13, Train Loss:13273.61115579044, Val Loss:17648.369047619046, 학습 시간: 25.53292155265808\n",
      "EPOCH:14, Train Loss:13013.753791360294, Val Loss:17781.6875, 학습 시간: 25.98278832435608\n",
      "EPOCH:15, Train Loss:12692.494415539653, Val Loss:17711.92992001488, 학습 시간: 25.734869241714478\n",
      "EPOCH:16, Train Loss:12462.79778591124, Val Loss:17990.53552827381, 학습 시간: 25.862547636032104\n",
      "EPOCH:17, Train Loss:12400.07068178834, Val Loss:17484.788969494046, 학습 시간: 25.844685316085815\n",
      "EPOCH:18, Train Loss:12095.56418231355, Val Loss:17879.9921875, 학습 시간: 25.471426248550415\n",
      "EPOCH:19, Train Loss:11851.64970538997, Val Loss:17565.692522321428, 학습 시간: 25.421061038970947\n",
      "EPOCH:20, Train Loss:11671.703925124737, Val Loss:17740.287248883928, 학습 시간: 25.46263313293457\n",
      "EPOCH:21, Train Loss:11484.699981945903, Val Loss:17627.303524925595, 학습 시간: 25.515567302703857\n",
      "EPOCH:22, Train Loss:11346.285365513393, Val Loss:17511.064313616072, 학습 시간: 25.863093614578247\n",
      "EPOCH:23, Train Loss:11203.738244321166, Val Loss:17767.175316220237, 학습 시간: 25.666313648223877\n",
      "EPOCH:24, Train Loss:11167.172314042804, Val Loss:17584.244931175595, 학습 시간: 25.787265062332153\n",
      "EPOCH:25, Train Loss:10986.710248161764, Val Loss:17635.335611979168, 학습 시간: 25.78715181350708\n",
      "EPOCH:26, Train Loss:10918.37639919249, Val Loss:17242.567429315477, 학습 시간: 25.756640672683716\n",
      "모델 저장\n",
      "EPOCH:27, Train Loss:10782.519962086397, Val Loss:17642.76488095238, 학습 시간: 25.54455041885376\n",
      "EPOCH:28, Train Loss:10658.852481617647, Val Loss:17706.974609375, 학습 시간: 25.442540884017944\n",
      "EPOCH:29, Train Loss:10604.185193999474, Val Loss:17639.2177734375, 학습 시간: 25.443027019500732\n",
      "EPOCH:30, Train Loss:10501.7698554031, Val Loss:17553.79371279762, 학습 시간: 25.4420268535614\n",
      "EPOCH:31, Train Loss:10331.630387506566, Val Loss:17669.856584821428, 학습 시간: 25.445266723632812\n",
      "EPOCH:32, Train Loss:10254.15899504333, Val Loss:17681.564964657737, 학습 시간: 25.63049006462097\n",
      "EPOCH:33, Train Loss:10156.853909532563, Val Loss:17682.544921875, 학습 시간: 25.77480173110962\n",
      "EPOCH:34, Train Loss:10083.595978039653, Val Loss:17939.017438616072, 학습 시간: 25.62992238998413\n",
      "EPOCH:35, Train Loss:9993.751189929097, Val Loss:17629.77808779762, 학습 시간: 25.7091064453125\n",
      "EPOCH:36, Train Loss:9922.21269367122, Val Loss:17837.033668154763, 학습 시간: 25.717697858810425\n",
      "EPOCH:37, Train Loss:9811.09750443146, Val Loss:17923.633975074405, 학습 시간: 25.698079586029053\n",
      "EPOCH:38, Train Loss:9832.497858127626, Val Loss:17938.999116443454, 학습 시간: 25.67421293258667\n",
      "EPOCH:39, Train Loss:9724.583984375, Val Loss:17667.574637276786, 학습 시간: 25.521012783050537\n",
      "EPOCH:40, Train Loss:9627.210367154674, Val Loss:17761.438430059523, 학습 시간: 25.435993671417236\n",
      "EPOCH:41, Train Loss:9593.584316734507, Val Loss:17874.70824032738, 학습 시간: 25.445155382156372\n",
      "EPOCH:42, Train Loss:9499.472348509717, Val Loss:17820.28585379464, 학습 시간: 25.449695587158203\n",
      "EPOCH:43, Train Loss:9496.19795906644, Val Loss:17670.326497395832, 학습 시간: 25.45239543914795\n",
      "EPOCH:44, Train Loss:9282.58784548976, Val Loss:17521.454055059523, 학습 시간: 25.46828055381775\n",
      "EPOCH:45, Train Loss:9279.11363002232, Val Loss:17772.622628348214, 학습 시간: 25.542877197265625\n",
      "EPOCH:46, Train Loss:9238.764102711397, Val Loss:17747.539109002977, 학습 시간: 25.68011999130249\n",
      "EPOCH:47, Train Loss:9162.184672892594, Val Loss:17870.99827938988, 학습 시간: 25.720438718795776\n",
      "EPOCH:48, Train Loss:9087.934389771533, Val Loss:17750.203683035714, 학습 시간: 25.525880336761475\n",
      "EPOCH:49, Train Loss:9006.911727777047, Val Loss:17726.81798735119, 학습 시간: 25.636284112930298\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-d3bae13d4fb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch_li\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_li\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-ab73b36796f3>\u001b[0m in \u001b[0;36mval\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-efe9c4a8b485>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mel_spec)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_conv7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m#print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfliplr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model_dir = '/home/work/Tcae_apply/model_dir/'\n",
    "min_loss = 987654321\n",
    "\n",
    "train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    start = time.time()\n",
    "    \n",
    "    #train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "    #val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "    train_loss = train(model = model, train_loader = train_batch_li) \n",
    "    val_loss = val(model = model, train_loader = val_batch_li) \n",
    "    end = time.time()\n",
    "\n",
    "    print(f'EPOCH:{epoch}, Train Loss:{train_loss}, Val Loss:{val_loss}, 학습 시간: {end - start}')\n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_dir + f'TimeAutoEncoder_val.pt')\n",
    "        print('모델 저장')\n",
    "        \n",
    "    #del train_batch_li\n",
    "    #del valid_batch_li\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = TimeAutoEncoder().to(DEVICE)\n",
    "#model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_val.pt', map_location = DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_embeding_li = get_mel_embeding(model = model, train_loader = test_batch_li)\n",
    "#mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(batch_data_dir + 'mel_embeding_val.npy', mel_embeding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
