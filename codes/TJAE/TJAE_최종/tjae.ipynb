{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6Zd03NSY3Uy6"},"outputs":[],"source":["import torchaudio\n","import torch \n","import pandas as pd\n","import numpy as np\n","import re \n","import os \n","from torch.nn import functional as F\n","import random\n","import math\n","import pickle\n","import gc\n","import torch.nn as nn\n","from tqdm.notebook import tqdm\n","import os\n","import glob\n","import warnings\n","from torch.utils.data import Dataset, DataLoader\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2LrDrxPJ3Uy8"},"outputs":[],"source":["base_dir = '/home/work/'\n","np1 = glob.glob(base_dir+'mel_dataset1/*.npy')\n","np2 = glob.glob(base_dir+'mel_dataset2/*.npy')\n","np3 = glob.glob(base_dir+'mel_dataset3/*.npy')\n","np4 = glob.glob(base_dir+'mel_dataset4/*.npy')\n","np5 = glob.glob(base_dir+'mel_dataset5/*.npy')\n","np6 = glob.glob(base_dir+'mel_dataset6/*.npy')\n","np7 = glob.glob(base_dir+'mel_dataset7/*.npy')\n","np8 = glob.glob(base_dir+'mel_dataset8/*.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jg8crYIV3Uy8"},"outputs":[],"source":["total = np1+np2+np3+np4+np5+np6+np7+np8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ifqnMAD3Uy8"},"outputs":[],"source":["train_csv = pd.read_csv('new_train.csv')\n","valid_csv = pd.read_csv('new_valid.csv')\n","all_csv =pd.read_csv('new_all.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["6341af5fa0a14195bfc9a7bd4e0ac362","5511ab959e7c48f5bc0a13e4e7bd57bd"]},"id":"VQddAbRm3Uy8","outputId":"8826b105-c392-40c4-e167-b85a85bb81ee"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6341af5fa0a14195bfc9a7bd4e0ac362","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3825 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5511ab959e7c48f5bc0a13e4e7bd57bd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/675 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def npy_list(csv):\n","    npy_list = []\n","    for song_path in tqdm(csv['npy_path']):\n","        song_npy = np.load(song_path).squeeze()\n","        #npy_list.append(song_npy[-1876:])\n","        npy_list.append(song_npy)\n","        \n","    return npy_list\n","\n","train_list = [np.load(song_path).squeeze() for song_path in tqdm(train_csv['npy_path'])]\n","valid_list = [np.load(song_path).squeeze() for song_path in tqdm(valid_csv['npy_path'])]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EEAocnkg3Uy9"},"outputs":[],"source":["all_list = train_list + valid_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WEy4R07a3Uy9","outputId":"e0848097-e546-4176-cb77-b2f843b5116a"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["\n","if torch.cuda.is_available():\n","    DEVICE = torch.device('cuda')\n","else:\n","    DEVICE = torch.device('cpu')\n","print(DEVICE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aqAGWtG3Uy9"},"outputs":[],"source":["def train(model, train_loader):\n","    model.train()\n","    train_loss = 0\n","    for batch in train_loader: \n","        \n","        \n","        mel = torch.FloatTensor(batch).to(DEVICE)\n","    \n","        optimizer.zero_grad()\n","        \n","        encode, output = model(mel)\n","        \n","        loss = criterion(output, mel)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        \n","    train_loss /= (len(train_loader))\n","\n","    return train_loss\n","\n","def val(model, train_loader):\n","    model.eval()\n","    val_loss = 0\n","\n","    with torch.no_grad():\n","        for batch in train_loader:\n","            \n","            \n","            mel = torch.FloatTensor(batch).to(DEVICE)\n","            \n","            encode, output = model(mel)\n","\n","            loss = criterion(output, mel)\n","            \n","            val_loss += loss.item()\n","\n","    val_loss /= (len(train_loader))\n","\n","    return val_loss\n","\n","\n","def get_mel_embeding(model, train_loader):\n","    model.eval()\n","    mel_embeding_li = []\n","    with torch.no_grad():\n","        for batch in train_loader: \n","            \n","            mel = torch.FloatTensor(batch).to(DEVICE)\n","            \n","            encode, output = model(mel)\n","            mel_embeding_li.append(encode.detach().cpu().numpy())\n","\n","    return mel_embeding_li"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRppflaL3Uy9"},"outputs":[],"source":["#charlie\n","class TimeAutoEncoder(nn.Module):\n","    def __init__(self):\n","        super(TimeAutoEncoder, self).__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(in_channels = 48, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","    \n","        self.conv2 = nn.Sequential(\n","            nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n","            #nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","        )\n","            \n","        self.conv3 = nn.Sequential(\n","            nn.Conv1d(in_channels = 256, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n","            #nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","        )\n","\n","        self.conv4 = nn.Sequential(\n","            nn.Conv1d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n","            #nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","        )\n","\n","        self.conv5 = nn.Sequential(\n","            nn.Conv1d(in_channels = 64, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n","            #nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","        )\n","\n","        self.conv6 = nn.Sequential(\n","            nn.Conv1d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n","            #nn.BatchNorm1d(16),\n","            nn.ReLU(),\n","        )\n","\n","        self.conv7 = nn.Sequential(\n","            nn.Conv1d(in_channels = 16, out_channels = 4, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n","            #nn.BatchNorm1d(8),\n","            nn.ReLU(),\n","        )\n","\n","        self.encoder_fc = nn.Sequential(\n","            nn.Linear(8 * 7501, 256),\n","            #nn.BatchNorm1d(128),\n","            nn.LeakyReLU(),\n","        )\n","        \n","        self.decoder_fc = nn.Sequential(\n","            nn.Linear(256, 8 * 7501),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv1 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 8, out_channels = 16, kernel_size  = 3, stride = 1, dilation=62),\n","            nn.Conv1d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 1),\n","            #nn.BatchNorm1d(16),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv2 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 16, out_channels = 32, kernel_size  = 3, stride = 1, dilation = 30),\n","            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 2),\n","            #nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv3 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 32, out_channels = 64, kernel_size  = 3, stride = 1, dilation=14),\n","            nn.Conv1d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n","            #nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv4 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 64, out_channels = 128, kernel_size  = 3, stride = 1, dilation = 6),\n","            nn.Conv1d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n","            #nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv5 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 128, out_channels = 256, kernel_size  = 3, stride = 1, dilation=2),\n","            nn.Conv1d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n","            #nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv6 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 256, out_channels = 512, kernel_size  = 3, stride = 1, dilation = 1),\n","            nn.Conv1d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","\n","        self.t_conv7 = nn.Sequential(\n","            # nn.ConvTranspose1d(in_channels = 512, out_channels = 48, kernel_size  = 3, stride = 1, dilation= 1),\n","            nn.Conv1d(in_channels = 1024, out_channels = 48, kernel_size = 3, stride = 1, padding = 0, dilation = 64)\n","        )\n","\n","        \n","        \n","        \n","        self.conv1to3 = nn.Sequential(\n","            nn.Conv1d(in_channels = 512, out_channels = 64, kernel_size = 3, stride = 1, padding = 0, dilation = 4),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","        \n","        self.conv2to4 = nn.Sequential(\n","            nn.Conv1d(in_channels = 256, out_channels = 32, kernel_size = 3, stride = 1, padding = 0, dilation = 8),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","        \n","        self.conv3to5 = nn.Sequential(\n","            nn.Conv1d(in_channels = 128, out_channels = 16, kernel_size = 3, stride = 1, padding = 0, dilation = 16),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","        \n","        self.conv4to6 = nn.Sequential(\n","            nn.Conv1d(in_channels = 64, out_channels = 8, kernel_size = 3, stride = 1, padding = 0, dilation = 32),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","        \n","        self.conv5to7 = nn.Sequential(\n","            nn.Conv1d(in_channels = 32, out_channels = 4, kernel_size = 3, stride = 1, padding = 0, dilation = 64),\n","            #nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","        )\n","        \n","        \n","        \n","    def forward(self, mel_spec):\n","        x = F.pad(mel_spec, pad = (2, 0, 0, 0))\n","        x1 = self.conv1(x) \n","        \n","        x1to2 = F.pad(x1, pad = (4, 0, 0, 0)) \n","        x1to3 = F.pad(x1, pad = (8, 0, 0, 0)) \n","        \n","        \n","        x2 = self.conv2(x1to2) \n","        \n","        x2to3 = F.pad(x2, pad = (8, 0, 0, 0)) \n","        \n","        x3 = self.conv3(x2to3) \n","        x3_connec = self.conv1to3(x1to3) \n","        x3= torch.cat([x3,x3_connec],1) \n","        \n","        \n","        x3to4 = F.pad(x3, pad = (16, 0, 0, 0))\n","        x3to5 = F.pad(x3, pad = (32, 0, 0, 0)) \n","        \n","        x4 = self.conv4(x3to4) \n","        \n","        x4to5 = F.pad(x4, pad = (32, 0, 0, 0)) \n","        \n","\n","        x5 = self.conv5(x4to5)  \n","        x5_connec = self.conv3to5(x3to5) \n","        x5 = torch.cat([x5,x5_connec],1) \n","        \n","        x5to6 = F.pad(x5, pad = (64, 0, 0, 0)) \n","        x5to7 = F.pad(x5, pad = (128, 0, 0, 0)) \n","        \n","        \n","        x6 = self.conv6(x5to6) \n","        x6to7 = F.pad(x6, pad = (128, 0, 0, 0)) \n","        \n","        x7 = self.conv7(x6to7) \n","        pre_encode = torch.flatten(x7)\n","        x7_connec = self.conv5to7(x5to7) \n","        x7 = torch.cat([x7,x7_connec],1) \n","        \n","        encode = self.encoder_fc(x7.view(-1, 8 * 7501))\n","\n","        x = self.decoder_fc(encode)\n","        x = x.view(-1, 8, 7501)\n","        \n","        \n","        x = torch.cat([x7,x],1) \n","        x = F.pad(x, pad = (2, 0, 0, 0)) \n","        x = self.t_conv1(x) \n","        \n","        x = torch.cat([x6,x],1)\n","        x = F.pad(x, pad = (4, 0, 0, 0))\n","        x = self.t_conv2(x)\n","        \n","        \n","        x = torch.cat([x5,x],1)\n","        x = F.pad(x, pad = (8, 0, 0, 0))\n","        x = self.t_conv3(x)\n","        \n","        \n","        \n","        x = torch.cat([x4,x],1)\n","        x = F.pad(x, pad = (16, 0, 0, 0))\n","        x = self.t_conv4(x)\n","        \n","        \n","        x = torch.cat([x3,x],1)\n","        x = F.pad(x, pad = (32, 0, 0, 0))\n","        x = self.t_conv5(x)\n","        \n","        \n","        \n","        x = torch.cat([x2,x],1)\n","        x = F.pad(x, pad = (64, 0, 0, 0))\n","        x = self.t_conv6(x)\n","        \n","        \n","        \n","        x = torch.cat([x1,x],1)\n","        x = F.pad(x, pad = (128, 0, 0, 0))\n","        x = self.t_conv7(x)\n","        \n","        return encode, x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1NCGgMz3Uy-"},"outputs":[],"source":["model = TimeAutoEncoder().to(DEVICE)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n","criterion = nn.MSELoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kifh6xx53Uy_","outputId":"87922cde-f414-48af-bed6-8020c62944c7"},"outputs":[{"data":{"text/plain":["26"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"colab":{"referenced_widgets":["6fc1b8baa9cb4930afd2aa8cdfad4b93"]},"id":"9yshnITF3Uy_","outputId":"75bfcf28-6ef5-4c78-ea98-e9455b2ff621"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fc1b8baa9cb4930afd2aa8cdfad4b93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/150 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["EPOCH:1, Train Loss:110260.32459309897, Val Loss:11433.421253551136, 학습 시간: 78.66790819168091\n","EPOCH:2, Train Loss:7394.33687133789, Val Loss:3800.166681463068, 학습 시간: 71.63565707206726\n","EPOCH:3, Train Loss:2928.3070871988934, Val Loss:1872.6620871803977, 학습 시간: 57.03754138946533\n","EPOCH:4, Train Loss:1687.3794443766276, Val Loss:1260.5794039639559, 학습 시간: 45.16006374359131\n","EPOCH:5, Train Loss:1121.6509796142577, Val Loss:912.6757535067471, 학습 시간: 36.65596675872803\n","EPOCH:6, Train Loss:864.2644838968913, Val Loss:726.4970619895241, 학습 시간: 35.88951921463013\n","EPOCH:7, Train Loss:682.7494117736817, Val Loss:561.0816653858532, 학습 시간: 35.71298885345459\n","EPOCH:8, Train Loss:554.2170783996582, Val Loss:519.9623315984553, 학습 시간: 35.77355408668518\n","EPOCH:9, Train Loss:607.3109842936198, Val Loss:447.49970176003194, 학습 시간: 35.61007761955261\n","EPOCH:10, Train Loss:477.72823333740234, Val Loss:532.4633622602983, 학습 시간: 35.18342614173889\n","EPOCH:11, Train Loss:401.6184939066569, Val Loss:347.6201789162376, 학습 시간: 34.695720195770264\n","EPOCH:12, Train Loss:323.973624420166, Val Loss:308.0288585316051, 학습 시간: 35.60895609855652\n","EPOCH:13, Train Loss:290.100657526652, Val Loss:268.275034124201, 학습 시간: 35.84679388999939\n","EPOCH:14, Train Loss:313.8174774169922, Val Loss:265.9197006225586, 학습 시간: 35.68574380874634\n","EPOCH:15, Train Loss:238.78607082366943, Val Loss:214.54939686168325, 학습 시간: 35.341413736343384\n","EPOCH:16, Train Loss:229.17393709818523, Val Loss:194.60092475197533, 학습 시간: 35.22715616226196\n","EPOCH:17, Train Loss:194.05967032114665, Val Loss:182.22713713212445, 학습 시간: 34.34017610549927\n","EPOCH:18, Train Loss:229.26340300242106, Val Loss:461.4044203324751, 학습 시간: 35.056241035461426\n","EPOCH:19, Train Loss:217.9830738067627, Val Loss:158.16957196322355, 학습 시간: 35.86855888366699\n","EPOCH:20, Train Loss:161.56976903279622, Val Loss:199.67559363625267, 학습 시간: 34.80478549003601\n","EPOCH:21, Train Loss:217.84127254486083, Val Loss:142.13414348255503, 학습 시간: 33.52404570579529\n","EPOCH:22, Train Loss:145.91367403666177, Val Loss:225.6616301103072, 학습 시간: 35.475128173828125\n","EPOCH:23, Train Loss:143.94332962036134, Val Loss:147.8850080316717, 학습 시간: 35.30222678184509\n","EPOCH:24, Train Loss:104.71568075815837, Val Loss:91.80353580821644, 학습 시간: 35.01532983779907\n","EPOCH:25, Train Loss:105.31534458796183, Val Loss:96.16325742548162, 학습 시간: 35.11035370826721\n","EPOCH:26, Train Loss:151.86355311075846, Val Loss:78.02237606048584, 학습 시간: 34.582892656326294\n","EPOCH:27, Train Loss:72.53471425374349, Val Loss:89.16891444813122, 학습 시간: 35.20557928085327\n","EPOCH:28, Train Loss:99.48459803263346, Val Loss:95.62714906172319, 학습 시간: 35.31842350959778\n","EPOCH:29, Train Loss:92.86581106185913, Val Loss:150.05311480435458, 학습 시간: 35.30153298377991\n","EPOCH:30, Train Loss:107.90639263788859, Val Loss:56.70880265669389, 학습 시간: 34.85111856460571\n","EPOCH:31, Train Loss:67.97554063796997, Val Loss:54.464982292868875, 학습 시간: 34.79559564590454\n","EPOCH:32, Train Loss:61.29490138689677, Val Loss:81.7488776770505, 학습 시간: 35.44403886795044\n","EPOCH:33, Train Loss:63.15171397527059, Val Loss:79.48076872392134, 학습 시간: 35.485153913497925\n","EPOCH:34, Train Loss:67.65611397425333, Val Loss:46.96646777066317, 학습 시간: 35.68626403808594\n","EPOCH:35, Train Loss:48.7513721148173, Val Loss:77.22865659540349, 학습 시간: 35.22290349006653\n","EPOCH:36, Train Loss:68.53959353764851, Val Loss:46.54348364743319, 학습 시간: 34.90697526931763\n","EPOCH:37, Train Loss:43.01157027880351, Val Loss:35.866590239784934, 학습 시간: 34.767130851745605\n","EPOCH:38, Train Loss:68.68327320416769, Val Loss:188.9869596307928, 학습 시간: 35.58491826057434\n","EPOCH:39, Train Loss:143.82795464197795, Val Loss:101.28138264742765, 학습 시간: 35.49625611305237\n","EPOCH:40, Train Loss:66.80655339558919, Val Loss:60.991954283280805, 학습 시간: 35.354564905166626\n","EPOCH:41, Train Loss:46.305172522862755, Val Loss:98.40654251792215, 학습 시간: 35.531562089920044\n","EPOCH:42, Train Loss:57.04865969022115, Val Loss:25.830465230074797, 학습 시간: 35.305041790008545\n","EPOCH:43, Train Loss:32.0077833255132, Val Loss:23.406921776858244, 학습 시간: 34.420860290527344\n","EPOCH:44, Train Loss:38.80158710479736, Val Loss:74.11419486999512, 학습 시간: 35.712918758392334\n","EPOCH:45, Train Loss:45.1844082514445, Val Loss:25.38695391741666, 학습 시간: 35.616586685180664\n","EPOCH:46, Train Loss:44.60436445871989, Val Loss:25.08222198486328, 학습 시간: 34.97810626029968\n","EPOCH:47, Train Loss:45.21771394411723, Val Loss:24.6423414403742, 학습 시간: 34.853801012039185\n","EPOCH:48, Train Loss:27.32829616069794, Val Loss:53.6351295817982, 학습 시간: 35.352527379989624\n","EPOCH:49, Train Loss:34.22537879149119, Val Loss:22.78279506076466, 학습 시간: 35.77957463264465\n","EPOCH:50, Train Loss:23.02162514527639, Val Loss:59.42874977805398, 학습 시간: 35.4737982749939\n","EPOCH:51, Train Loss:37.06577712694804, Val Loss:38.73234558105469, 학습 시간: 35.67736101150513\n","EPOCH:52, Train Loss:33.9316548426946, Val Loss:29.670434431596235, 학습 시간: 35.03521752357483\n","EPOCH:53, Train Loss:31.45626520315806, Val Loss:26.568250135941938, 학습 시간: 33.875489711761475\n","EPOCH:54, Train Loss:32.23313686450322, Val Loss:24.77866198799827, 학습 시간: 35.46911597251892\n","EPOCH:55, Train Loss:34.073598353068036, Val Loss:26.20751840418035, 학습 시간: 35.54521298408508\n","EPOCH:56, Train Loss:30.35326550801595, Val Loss:54.20743335377086, 학습 시간: 34.89288687705994\n","EPOCH:57, Train Loss:32.4016523996989, Val Loss:33.812978050925516, 학습 시간: 34.55040740966797\n","EPOCH:58, Train Loss:37.222225308418274, Val Loss:42.639436375011094, 학습 시간: 35.19183135032654\n","EPOCH:59, Train Loss:46.42012972036998, Val Loss:12.13205692984841, 학습 시간: 35.677332639694214\n","EPOCH:60, Train Loss:19.22078630924225, Val Loss:31.546971321105957, 학습 시간: 35.495057106018066\n","EPOCH:61, Train Loss:31.513877081871033, Val Loss:24.111403378573332, 학습 시간: 34.61081647872925\n","EPOCH:62, Train Loss:31.133535917599996, Val Loss:11.26998582753268, 학습 시간: 34.81570625305176\n","EPOCH:63, Train Loss:23.75294318596522, Val Loss:11.85514428398826, 학습 시간: 35.254311084747314\n"]}],"source":["\n","import time\n","\n","model_dir = '/home/work/Tcae_apply/model_dir3/'\n","min_loss = 987654321\n","\n","epochs = 150\n","batch_size = 32\n","\n","train_batch_li = DataLoader(train_list, batch_size=batch_size, shuffle=True,drop_last=False)\n","val_batch_li = DataLoader(valid_list, batch_size=batch_size, shuffle=True,drop_last=False)\n","\n","for epoch in tqdm(range(1, epochs + 1)):\n","    start = time.time()\n","    \n","    \n","    train_loss = train(model = model, train_loader = train_batch_li) \n","    val_loss = val(model = model, train_loader = val_batch_li) \n","    end = time.time()\n","    \n","    print(f'EPOCH:{epoch}, Train Loss:{train_loss}, Val Loss:{val_loss}, 학습 시간: {end - start}')\n","    if (val_loss < min_loss) & (val_loss < 10) & (train_loss < 15) :\n","        min_loss = val_loss\n","        torch.save(model.state_dict(), model_dir + f'TimeAutoEncoder_skipconnection_charlie_val.pt')\n","        print('모델 저장')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldOY9ocg3Uy_","outputId":"96ac7de2-07b2-42a3-8b16-ea1f2b8948a2"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model_dir = '/home/work/Tcae_apply/model_dir/'\n","\n","model = TimeAutoEncoder().to(DEVICE)\n","model.load_state_dict(torch.load(model_dir + f'TimeAutoEncoder_skipconnection_charlie_val.pt', map_location = DEVICE))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWTZ-5Qx3Uy_"},"outputs":[],"source":["test_batch_li = DataLoader(all_list, batch_size=1, shuffle=False,drop_last=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"OPurCmDO3Uy_"},"outputs":[],"source":["mel_embeding_li = get_mel_embeding(model = model, train_loader = test_batch_li)\n","mel_embeding = np.concatenate(mel_embeding_li, axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHFcUg1J3Uy_"},"outputs":[],"source":["pd.DataFrame(mel_embeding).to_csv('tcae_charlie_embedding.csv',index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CC9PFu_H3Uy_"},"outputs":[],"source":["import glob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xxyAjJjN3UzA"},"outputs":[],"source":["inference_npy_path = '/home/work/Tcae_apply/tcae_inference_folder/mel_folder/'\n","inference_npy_path = glob.glob(inference_npy_path + '*.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["57e6ea3670c047d3b6b6559ccf032cfb"]},"id":"jEeSS-4M3UzA","outputId":"ade2361f-f0f2-491a-8756-1d6bbf163246"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57e6ea3670c047d3b6b6559ccf032cfb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["inference_list = [np.load(song_path).squeeze()[:,:7501] for song_path in tqdm(inference_npy_path)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6RwggG_v3UzA"},"outputs":[],"source":["inference_batch_li = DataLoader(inference_list, batch_size=1, shuffle=False,drop_last=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dG-m93oW3UzA"},"outputs":[],"source":["def get_mel_inference_embeding(model, train_loader):\n","    model.eval()\n","    mel_embeding_li = []\n","    with torch.no_grad():\n","        for batch in train_loader: \n","            \n","            mel = torch.FloatTensor(batch).to(DEVICE)\n"," \n","            encode, output = model(mel)\n","            mel_embeding_li.append(encode.detach().cpu().numpy())\n","\n","    return mel_embeding_li"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"8drr-C3b3UzA"},"outputs":[],"source":["inference_embedding_li = get_mel_embeding(model = model, train_loader = inference_batch_li)\n","inference_embedding = np.concatenate(inference_embedding_li, axis = 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"otDMdEv_3UzA"},"outputs":[],"source":["pd.DataFrame(inference_embedding).to_csv('inference_embedding1.csv',index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}